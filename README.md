ğŸš˜ Advanced Driver Assistance System (ADAS) â€” Computer Vision Based

A modular, real-time ADAS suite built using YOLOv8 segmentation, DeepSORT tracking, lane detection, speed estimation, TTC warnings and AI-powered HUD.

ğŸ“Œ Overview

This project implements a real-time ADAS pipeline using computer vision, deep learning and classical image processing.
The system works on dashcam / bike / car videos and provides essential road-safety features such as:

Lane detection & departure warnings

Object detection with segmentation

Multi-object tracking

Speed & relative distance estimation

Time-To-Collision (TTC) warnings

On-screen HUD visualization

Traffic-light detection (color-based prototype)

The project was built and tested on Indian roads using the IDD-Lite dataset.

ğŸš€ Features Implemented
âœ” 1. Semantic Segmentation (YOLOv8-Seg)

Custom-trained YOLOv8n-seg model on IDD-Lite

7-class segmentation (drivable, non-drivable, vehicles, pedestrians, etc.)

âœ” 2. Object Tracking (DeepSORT)

Unique ID assignment

Smooth tracking across frames

Re-identification embeddings

âœ” 3. Speed Estimation / Relative Velocity

Pixel-to-meter calibration

Frame-to-frame object displacement

Speed output in km/h

CSV export

âœ” 4. Time-To-Collision (TTC)

TTC = distance / relative speed

Real-time warning system

Alerts displayed in HUD

Event logging

âœ” 5. Lane Detection

Canny edge + Hough lines

Segmentation-based hood removal

Lane departure detection

Lane deviation warning

âœ” 6. ADAS HUD Overlay

Includes overlay elements:

TTC in seconds

Object ID with speed

Bounding boxes with segmentation colors

Lane centerline

Warning text

âœ” 7. Traffic Light Detection (Prototype)

Color-based (Red / Yellow / Green)

Upper-ROI filtering

Shape + area filtering

Non-blocking (optional)

ğŸ—‚ Project Structure
adas_project/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ adas_lane.ipynb
â”‚   â”œâ”€â”€ adas_tracking.ipynb
â”‚   â”œâ”€â”€ adas_full_pipeline.ipynb
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_adas_demo.py
â”‚   â”œâ”€â”€ lane_detector.py
â”‚   â”œâ”€â”€ ttc_tracker.py
â”‚   â”œâ”€â”€ speed_estimator.py
â”‚   â”œâ”€â”€ tl_detector.py
â”‚   â””â”€â”€ segmentation_utils.py
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ paths.yaml
â”‚   â””â”€â”€ model_config.yaml
â”‚
â”œâ”€â”€ run_yolov8n_seg2/
â”‚   â”œâ”€â”€ weights/
â”‚   â”œâ”€â”€ preds_viz/
â”‚   â”œâ”€â”€ tracks_kmh_final.csv
â”‚   â”œâ”€â”€ output_riding_bike.mp4
â”‚   â””â”€â”€ output_riding_bike_track_final.mp4
â”‚
â”œâ”€â”€ data/  (ignored)
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .gitattributes
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

âš™ï¸ Installation
1ï¸âƒ£ Create Conda environment
conda create -n adas python=3.10 -y
conda activate adas

2ï¸âƒ£ Install dependencies
pip install -r requirements.txt

3ï¸âƒ£ Install torch (if missing)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

ğŸ“¥ Dataset Setup (IDD-Lite)

Download IDD-Lite:
https://idd.insaan.iiit.ac.in/dataset/details/

Place it here:

E:/projects/adas_local/data/idd_lite


Dataset is ignored in GitHub via .gitignore.

â–¶ï¸ Running the ADAS Pipeline
1ï¸âƒ£ Run segmentation + tracking + TTC + lane detection + HUD:
python scripts/run_adas_demo.py --video input.mp4

2ï¸âƒ£ Output files:
output_riding_bike_track_kmh_final.mp4
tracks_kmh_final.csv
output_riding_bike_ttc.mp4

ğŸ›£ Roadmap (Planned Features)

 *Blind Spot Detection (BSD)

 *Automatic Helmet Detection

 *Curved lane polynomial fitting

 *Full Traffic Light Recognition (YOLO-based)

 *Ego-motion stabilization

 *MiDaS depth-based distance estimation

 *Driver monitoring system

 *Mobile app integration


 This project is released under the MIT License.
Feel free to use, modify, and distribute.

â­ Acknowledgements

IDD Dataset

Ultralytics YOLOv8

DeepSORT Realtime

OpenCV

PyTorch

Navonil Mandal,Me :) ğŸš€
