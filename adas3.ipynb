{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ed05b78-a2b2-44f0-8a9a-10840cb0f61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: C:\\Users\\Dell\\projects\\idas_lite_seg\\run_yolov8n_seg2\\weights\\best.pt\n",
      "Video: 1280x720, 29.97002997002997 FPS\n",
      "\n",
      "DONE!\n",
      "Saved output video to: C:\\Users\\Dell\\projects\\idas_lite_seg\\run_yolov8n_seg2\\output_riding_bike.mp4\n",
      "Processed 0 frames in 25.37s (25.373 sec/frame).\n"
     ]
    }
   ],
   "source": [
    "# VIDEO SEGMENTATION DEMO (YOLOv8-seg)\n",
    "# Kernel: Python (adas)\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# -------- CONFIG --------\n",
    "BEST_WEIGHTS = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/weights/best.pt\")  # your model\n",
    "INPUT_VIDEO  = Path(r\"E:/projects/riding_bike.mp4\")  # <-- your video here\n",
    "OUTPUT_VIDEO = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/output_riding_bike.mp4\")\n",
    "DEVICE = \"cuda\"  # or \"cpu\"\n",
    "\n",
    "# -------- CHECKS --------\n",
    "if not BEST_WEIGHTS.exists():\n",
    "    raise SystemExit(\"best.pt not found at: \" + str(BEST_WEIGHTS))\n",
    "if not INPUT_VIDEO.exists():\n",
    "    raise SystemExit(\"Input video not found: \" + str(INPUT_VIDEO))\n",
    "\n",
    "print(\"Loading model:\", BEST_WEIGHTS)\n",
    "model = YOLO(str(BEST_WEIGHTS))\n",
    "\n",
    "# -------- VIDEO SETUP --------\n",
    "cap = cv2.VideoCapture(str(INPUT_VIDEO))\n",
    "W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "FPS = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "print(f\"Video: {W}x{H}, {FPS} FPS\")\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out = cv2.VideoWriter(str(OUTPUT_VIDEO), fourcc, FPS, (W, H))\n",
    "\n",
    "# colormap for segmentation\n",
    "cmap = np.random.RandomState(0).randint(0,255,(256,3),dtype=np.uint8)\n",
    "\n",
    "# -------- PROCESS LOOP --------\n",
    "frame_id = 0\n",
    "t0 = time.time()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # run segmentation\n",
    "    results = model.predict(frame, device=DEVICE, imgsz=640, conf=0.25, verbose=False)\n",
    "    r = results[0]\n",
    "\n",
    "    # extract mask (semantic)\n",
    "    mask = None\n",
    "    try:\n",
    "        if hasattr(r, \"masks\") and r.masks is not None:\n",
    "            mdata = r.masks.data if hasattr(r.masks, \"data\") else r.masks.numpy()\n",
    "            arr = np.array(mdata)\n",
    "            if arr.ndim == 3:\n",
    "                mask = np.argmax(arr, axis=0).astype(np.int32)\n",
    "            elif arr.ndim == 2:\n",
    "                mask = arr.astype(np.int32)\n",
    "    except Exception:\n",
    "        mask = None\n",
    "\n",
    "    if mask is None:\n",
    "        out.write(frame)\n",
    "        continue\n",
    "\n",
    "    # resize mask to original frame\n",
    "    mask = cv2.resize(mask.astype(np.int32), (W, H), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # colorize + overlay\n",
    "    mask_mod = np.mod(mask, 256).astype(np.uint8)\n",
    "    color_mask = cmap[mask_mod]\n",
    "    overlay = (0.5 * frame + 0.5 * color_mask).astype(np.uint8)\n",
    "\n",
    "    out.write(overlay)\n",
    "\n",
    "    frame_id += 1\n",
    "    if frame_id % 50 == 0:\n",
    "        print(\"Processed:\", frame_id, \"frames\")\n",
    "\n",
    "t1 = time.time()\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(\"\\nDONE!\")\n",
    "print(\"Saved output video to:\", OUTPUT_VIDEO)\n",
    "print(f\"Processed {frame_id} frames in {(t1 - t0):.2f}s ({(t1 - t0)/max(1,frame_id):.3f} sec/frame).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac33ca17-ada6-4801-879b-ecc8f277a1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: C:\\Users\\Dell\\projects\\idas_lite_seg\\run_yolov8n_seg2\\weights\\best.pt\n",
      "Video: 1280x720, 29.97 FPS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_5308\\3238078257.py:72: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  arr = np.array(mdata)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 frames...\n",
      "Processed 200 frames...\n",
      "Processed 300 frames...\n",
      "Processed 400 frames...\n",
      "Processed 500 frames...\n",
      "Processed 600 frames...\n",
      "Processed 700 frames...\n",
      "Processed 800 frames...\n",
      "\n",
      "DONE!\n",
      "Saved output video to: C:\\Users\\Dell\\projects\\idas_lite_seg\\run_yolov8n_seg2\\output_riding_bike_fixed.mp4\n",
      "Processed 870 frames in 25.01s (0.029 sec/frame).\n"
     ]
    }
   ],
   "source": [
    "# Fixed VIDEO SEGMENTATION DEMO (YOLOv8-seg) — handles BGR→RGB, robust mask extraction, always counts frames\n",
    "# Kernel: Python (adas)\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# -------- CONFIG --------\n",
    "BEST_WEIGHTS = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/weights/best.pt\")\n",
    "INPUT_VIDEO  = Path(r\"E:/projects/riding_bike.mp4\")\n",
    "OUTPUT_VIDEO = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/output_riding_bike_fixed.mp4\")\n",
    "DEVICE = \"cuda\"  # or \"cpu\"\n",
    "\n",
    "# -------- CHECKS --------\n",
    "if not BEST_WEIGHTS.exists():\n",
    "    raise SystemExit(\"best.pt not found at: \" + str(BEST_WEIGHTS))\n",
    "if not INPUT_VIDEO.exists():\n",
    "    raise SystemExit(\"Input video not found: \" + str(INPUT_VIDEO))\n",
    "\n",
    "print(\"Loading model:\", BEST_WEIGHTS)\n",
    "model = YOLO(str(BEST_WEIGHTS))\n",
    "\n",
    "# -------- VIDEO SETUP --------\n",
    "cap = cv2.VideoCapture(str(INPUT_VIDEO))\n",
    "if not cap.isOpened():\n",
    "    raise SystemExit(\"Failed to open video with OpenCV: \" + str(INPUT_VIDEO))\n",
    "\n",
    "W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "FPS = cap.get(cv2.CAP_PROP_FPS) or 25.0\n",
    "\n",
    "print(f\"Video: {W}x{H}, {FPS:.2f} FPS\")\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out = cv2.VideoWriter(str(OUTPUT_VIDEO), fourcc, FPS, (W, H))\n",
    "\n",
    "# colormap for segmentation\n",
    "cmap = np.random.RandomState(0).randint(0,255,(256,3),dtype=np.uint8)\n",
    "\n",
    "# -------- PROCESS LOOP --------\n",
    "frame_id = 0\n",
    "t0 = time.time()\n",
    "print_interval = 100\n",
    "\n",
    "while True:\n",
    "    ret, frame_bgr = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # convert to RGB for the model\n",
    "    frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # run segmentation (pass RGB array)\n",
    "    try:\n",
    "        results = model.predict(frame_rgb, device=DEVICE, imgsz=640, conf=0.25, verbose=False)\n",
    "    except Exception as ex:\n",
    "        # if predict fails for arrays, try passing frame path fallback (slower)\n",
    "        print(f\"[WARN] model.predict on array failed at frame {frame_id}: {ex}\", file=sys.stderr)\n",
    "        results = None\n",
    "\n",
    "    mask = None\n",
    "    if results:\n",
    "        r = results[0]\n",
    "        # robust extraction attempts\n",
    "        try:\n",
    "            if hasattr(r, \"masks\") and r.masks is not None:\n",
    "                # prefer r.masks.data if available\n",
    "                mdata = r.masks.data if hasattr(r.masks, \"data\") else getattr(r.masks, \"numpy\", lambda: r.masks)()\n",
    "                arr = np.array(mdata)\n",
    "                if arr.ndim == 3:\n",
    "                    # instance masks N,H,W -> convert to semantic-like via argmax\n",
    "                    mask = np.argmax(arr, axis=0).astype(np.int32)\n",
    "                elif arr.ndim == 2:\n",
    "                    mask = arr.astype(np.int32)\n",
    "                else:\n",
    "                    mask = np.squeeze(arr).astype(np.int32)\n",
    "        except Exception:\n",
    "            mask = None\n",
    "\n",
    "    # If mask still None, we will write original frame (but still count it)\n",
    "    if mask is None:\n",
    "        out_frame = frame_bgr  # write original BGR frame\n",
    "    else:\n",
    "        # resize mask to original frame size\n",
    "        if mask.shape[:2] != (H, W):\n",
    "            mask = cv2.resize(mask.astype(np.int32), (W, H), interpolation=cv2.INTER_NEAREST)\n",
    "        mask_mod = np.mod(mask, 256).astype(np.uint8)\n",
    "        color_mask = cmap[mask_mod]\n",
    "        # overlay color mask over original BGR frame -> need BGR for writer\n",
    "        overlay_rgb = (0.5 * frame_rgb + 0.5 * color_mask).astype(np.uint8)\n",
    "        out_frame = cv2.cvtColor(overlay_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    out.write(out_frame)\n",
    "\n",
    "    frame_id += 1\n",
    "    if frame_id % print_interval == 0:\n",
    "        print(f\"Processed {frame_id} frames...\")\n",
    "\n",
    "# clean up\n",
    "t1 = time.time()\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(\"\\nDONE!\")\n",
    "print(\"Saved output video to:\", OUTPUT_VIDEO)\n",
    "print(f\"Processed {frame_id} frames in {(t1 - t0):.2f}s ({(t1 - t0)/max(1,frame_id):.3f} sec/frame).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b007ac5-fec7-428d-8aab-5a292a18017d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics 8.3.228\n",
      "cv2 4.12.0\n",
      "deep_sort_realtime import OK\n"
     ]
    }
   ],
   "source": [
    "# Quick import test — run inside your notebook (kernel: Python (adas)) or in Anaconda Prompt (adas active)\n",
    "try:\n",
    "    import ultralytics, cv2, numpy as np\n",
    "    from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "    print(\"ultralytics\", ultralytics.__version__)\n",
    "    print(\"cv2\", cv2.__version__)\n",
    "    print(\"deep_sort_realtime import OK\")\n",
    "except Exception as e:\n",
    "    print(\"Import failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbae2d04-4adb-4959-a8d6-aa654278502f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation overlay ENABLED\n",
      "Starting detection+tracking (final)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_5308\\425739454.py:63: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  arr = np.array(rseg.masks.data if hasattr(rseg.masks, \"data\") else rseg.masks.numpy())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Saved to: C:\\Users\\Dell\\projects\\idas_lite_seg\\run_yolov8n_seg2\\output_riding_bike_track_final.mp4\n",
      "Frames: 870 Time: 62.04981756210327 FPS: 14.020992070270804\n"
     ]
    }
   ],
   "source": [
    "# Robust Detection + DeepSORT tracking + segmentation overlay (fixed color/type issues)\n",
    "# Kernel: Python (adas)\n",
    "\n",
    "from pathlib import Path\n",
    "import cv2, time, numpy as np, math, sys\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "# ----------------- CONFIG -----------------\n",
    "DETECT_WEIGHTS = \"yolov8n.pt\"\n",
    "SEG_WEIGHTS    = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/weights/best.pt\")\n",
    "INPUT_VIDEO    = Path(r\"E:/projects/riding_bike.mp4\")\n",
    "OUTPUT_VIDEO   = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/output_riding_bike_track_final.mp4\")\n",
    "DEVICE         = \"cuda\"\n",
    "CONF_THRESH    = 0.3\n",
    "\n",
    "# ----------------- Sanity checks -----------------\n",
    "if not INPUT_VIDEO.exists():\n",
    "    raise SystemExit(\"Input video not found: \" + str(INPUT_VIDEO))\n",
    "\n",
    "# ----------------- Load models -----------------\n",
    "det_model = YOLO(DETECT_WEIGHTS)\n",
    "seg_model = None\n",
    "if SEG_WEIGHTS is not None and SEG_WEIGHTS.exists():\n",
    "    seg_model = YOLO(str(SEG_WEIGHTS))\n",
    "    print(\"Segmentation overlay ENABLED\")\n",
    "else:\n",
    "    print(\"Segmentation overlay DISABLED\")\n",
    "\n",
    "# ----------------- Tracker -----------------\n",
    "tracker = DeepSort(max_age=30)\n",
    "\n",
    "# ----------------- Video IO -----------------\n",
    "cap = cv2.VideoCapture(str(INPUT_VIDEO))\n",
    "if not cap.isOpened():\n",
    "    raise SystemExit(\"Failed to open video: \" + str(INPUT_VIDEO))\n",
    "W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)); H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "FPS = cap.get(cv2.CAP_PROP_FPS) or 25.0\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "out = cv2.VideoWriter(str(OUTPUT_VIDEO), fourcc, FPS, (W, H))\n",
    "\n",
    "# Prepare palette as list of Python tuples (int,int,int) to avoid NumPy / dtype issues\n",
    "_palette_np = (np.random.RandomState(2).randint(0,255,(256,3))).astype(np.int32)\n",
    "PALETTE = [ (int(c[0]), int(c[1]), int(c[2])) for c in _palette_np ]\n",
    "\n",
    "last_centroid = {}\n",
    "frame_id = 0; t0 = time.time()\n",
    "\n",
    "print(\"Starting detection+tracking (final)...\")\n",
    "while True:\n",
    "    ret, frame_bgr = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    t_frame = time.time()\n",
    "    frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # segmentation (optional)\n",
    "    seg_mask = None\n",
    "    if seg_model is not None:\n",
    "        try:\n",
    "            rseg = seg_model.predict(frame_rgb, device=DEVICE, imgsz=640, verbose=False)[0]\n",
    "            if hasattr(rseg, \"masks\") and rseg.masks is not None:\n",
    "                arr = np.array(rseg.masks.data if hasattr(rseg.masks, \"data\") else rseg.masks.numpy())\n",
    "                seg_mask = np.argmax(arr, axis=0).astype(np.int32) if arr.ndim==3 else arr.astype(np.int32)\n",
    "        except Exception:\n",
    "            seg_mask = None\n",
    "\n",
    "    # detection -> DeepSort format: ([x1,y1,x2,y2], score, class_name)\n",
    "    detections_for_tracker = []\n",
    "    try:\n",
    "        r = det_model.predict(frame_rgb, device=DEVICE, imgsz=640, conf=CONF_THRESH, verbose=False)[0]\n",
    "        if hasattr(r, \"boxes\") and r.boxes is not None:\n",
    "            xyxy = r.boxes.xyxy.cpu().numpy() if hasattr(r.boxes, \"xyxy\") else np.array(r.boxes.xyxy)\n",
    "            confs = r.boxes.conf.cpu().numpy() if hasattr(r.boxes, \"conf\") else np.array(r.boxes.conf)\n",
    "            clsids = r.boxes.cls.cpu().numpy() if hasattr(r.boxes, \"cls\") else np.array(r.boxes.cls)\n",
    "            for (x1,y1,x2,y2), conf, clsid in zip(xyxy, confs, clsids):\n",
    "                detections_for_tracker.append(([float(x1), float(y1), float(x2), float(y2)], float(conf), str(int(clsid))))\n",
    "    except Exception as ex:\n",
    "        print(\"[WARN] detection error:\", ex, file=sys.stderr)\n",
    "        detections_for_tracker = []\n",
    "\n",
    "    # update tracker (pass BGR frame for appearance)\n",
    "    tracks = tracker.update_tracks(detections_for_tracker, frame=frame_bgr)\n",
    "\n",
    "    # draw tracks\n",
    "    for tr in tracks:\n",
    "        try:\n",
    "            if not tr.is_confirmed():\n",
    "                continue\n",
    "        except Exception:\n",
    "            # some tracker versions don't have is_confirmed method; assume confirmed\n",
    "            pass\n",
    "\n",
    "        # ensure track id is an int\n",
    "        try:\n",
    "            tid_raw = tr.track_id\n",
    "            tid = int(tid_raw)\n",
    "        except Exception:\n",
    "            # fallback if track_id is non-numeric\n",
    "            tid = abs(hash(str(tr.track_id))) % 10000\n",
    "\n",
    "        # get bbox (prefer ltrb)\n",
    "        try:\n",
    "            ltrb = tr.to_ltrb()\n",
    "        except Exception:\n",
    "            ltrb = tr.to_tlbr()\n",
    "        x1,y1,x2,y2 = map(int, ltrb)\n",
    "\n",
    "        # safe color selection (palette is list)\n",
    "        color = PALETTE[tid % len(PALETTE)]\n",
    "\n",
    "        cv2.rectangle(frame_bgr, (x1,y1), (x2,y2), color, 2)\n",
    "\n",
    "        cx = int((x1 + x2) / 2)\n",
    "        cy = int((y1 + y2) / 2)\n",
    "        speed_text = \"\"\n",
    "        if tid in last_centroid:\n",
    "            px, py, t_prev = last_centroid[tid]\n",
    "            dt = max(1e-6, t_frame - t_prev)\n",
    "            dist = math.hypot(cx - px, cy - py)\n",
    "            speed = dist / dt\n",
    "            speed_text = f\"{int(speed)} px/s\"\n",
    "        last_centroid[tid] = (cx, cy, t_frame)\n",
    "\n",
    "        label = f\"ID:{tid} {speed_text}\"\n",
    "        # draw label background for readability\n",
    "        (tw, th), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "        bx1, by1 = x1, max(0, y1 - th - 6)\n",
    "        bx2, by2 = x1 + tw + 6, by1 + th + 6\n",
    "        cv2.rectangle(frame_bgr, (bx1, by1), (bx2, by2), color, -1)\n",
    "        cv2.putText(frame_bgr, label, (x1+3, by2-4), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "    # overlay segmentation if present\n",
    "    frame_out = frame_bgr\n",
    "    if seg_mask is not None:\n",
    "        if seg_mask.shape[:2] != (H, W):\n",
    "            seg_mask = cv2.resize(seg_mask.astype(np.int32), (W, H), interpolation=cv2.INTER_NEAREST)\n",
    "        seg_col = (np.random.RandomState(0).randint(0,255,(256,3))).astype(np.uint8)\n",
    "        color_mask = seg_col[np.mod(seg_mask.astype(np.int32),256)]\n",
    "        frame_out = (0.4 * frame_bgr.astype(np.float32) + 0.6 * color_mask.astype(np.float32)).astype(np.uint8)\n",
    "\n",
    "    out.write(frame_out)\n",
    "    frame_id += 1\n",
    "\n",
    "# cleanup\n",
    "cap.release()\n",
    "out.release()\n",
    "t1 = time.time()\n",
    "print(\"Done. Saved to:\", OUTPUT_VIDEO)\n",
    "print(\"Frames:\", frame_id, \"Time:\", (t1 - t0), \"FPS:\", frame_id / max(1, (t1 - t0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d4dba70-1d3c-41d0-b57e-64b9fa9d467a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click TWO points on the frame, then press 'q' to continue.\n",
      "Selected point: (330, 288)\n",
      "Selected point: (545, 460)\n",
      "Pixel distance = 275.3343422096125\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter real distance between the two points (meters):  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration OK:  55.066868441922495 pixels per meter\n"
     ]
    }
   ],
   "source": [
    "# Calibration using OpenCV mouse clicks (works in Jupyter)\n",
    "# Click exactly TWO points in the window, then press 'q'\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "VIDEO_PATH = r\"E:/projects/riding_bike.mp4\"\n",
    "\n",
    "# Read first frame\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "ret, frame = cap.read()\n",
    "cap.release()\n",
    "\n",
    "if not ret:\n",
    "    raise SystemExit(\"Could not read video.\")\n",
    "\n",
    "points = []\n",
    "\n",
    "def click_event(event, x, y, flags, param):\n",
    "    global points\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        points.append((x, y))\n",
    "        print(f\"Selected point: {(x,y)}\")\n",
    "\n",
    "# Show frame\n",
    "cv2.namedWindow(\"Calibration\")\n",
    "cv2.setMouseCallback(\"Calibration\", click_event)\n",
    "\n",
    "print(\"Click TWO points on the frame, then press 'q' to continue.\")\n",
    "\n",
    "while True:\n",
    "    cv2.imshow(\"Calibration\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "if len(points) != 2:\n",
    "    raise SystemExit(\"ERROR: You must click exactly TWO points.\")\n",
    "\n",
    "p1, p2 = points\n",
    "pixel_dist = math.hypot(p2[0]-p1[0], p2[1]-p1[1])\n",
    "print(\"Pixel distance =\", pixel_dist)\n",
    "\n",
    "real_m = float(input(\"Enter real distance between the two points (meters): \"))\n",
    "\n",
    "px_per_m = pixel_dist / real_m\n",
    "print(\"Calibration OK: \", px_per_m, \"pixels per meter\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "489a1b37-2374-4ebe-82e6-ce38039aa69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seg overlay ENABLED using: C:\\Users\\Dell\\projects\\idas_lite_seg\\run_yolov8n_seg2\\weights\\best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\adas\\lib\\site-packages\\deep_sort_realtime\\embedder\\embedder_pytorch.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model.load_state_dict(torch.load(model_wts_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running calibrated tracker -> KM/H overlay. This may take some minutes depending on GPU/CPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_5308\\763140910.py:73: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  arr = np.array(rseg.masks.data if hasattr(rseg.masks, \"data\") else rseg.masks.numpy())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Saved video: C:\\Users\\Dell\\projects\\idas_lite_seg\\run_yolov8n_seg2\\output_riding_bike_track_kmh_final.mp4\n",
      "Saved CSV: C:\\Users\\Dell\\projects\\idas_lite_seg\\run_yolov8n_seg2\\tracks_kmh_final.csv\n",
      "Frames: 870, Total time: 50.6s, Achieved FPS: 17.21\n"
     ]
    }
   ],
   "source": [
    "# Calibrated tracking -> outputs KM/H overlay + CSV\n",
    "# Kernel: Python (adas)\n",
    "\n",
    "from pathlib import Path\n",
    "import cv2, time, math, csv, numpy as np, sys\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "# -------- CONFIG (edit if needed) --------\n",
    "INPUT_VIDEO  = Path(r\"E:/projects/riding_bike.mp4\")\n",
    "OUTPUT_VIDEO = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/output_riding_bike_track_kmh_final.mp4\")\n",
    "TRACKS_CSV   = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/tracks_kmh_final.csv\")\n",
    "\n",
    "DETECT_WEIGHTS = \"yolov8n.pt\"\n",
    "SEG_WEIGHTS = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/weights/best.pt\")  # set to None to disable\n",
    "DEVICE = \"cuda\"   # or \"cpu\"\n",
    "CONF_THRESH = 0.3\n",
    "\n",
    "# Use the px_per_m you measured\n",
    "PX_PER_M = 55.066868441922495   # <-- from your calibration (pixels per meter)\n",
    "\n",
    "# -------- Sanity checks --------\n",
    "if not INPUT_VIDEO.exists():\n",
    "    raise SystemExit(\"Input video missing: \" + str(INPUT_VIDEO))\n",
    "\n",
    "# -------- Load models --------\n",
    "det_model = YOLO(DETECT_WEIGHTS)\n",
    "seg_model = None\n",
    "if SEG_WEIGHTS is not None and SEG_WEIGHTS.exists():\n",
    "    seg_model = YOLO(str(SEG_WEIGHTS))\n",
    "    print(\"Seg overlay ENABLED using:\", SEG_WEIGHTS)\n",
    "else:\n",
    "    print(\"Seg overlay DISABLED\")\n",
    "\n",
    "# -------- Tracker setup --------\n",
    "tracker = DeepSort(max_age=30)\n",
    "\n",
    "# -------- Video IO --------\n",
    "cap = cv2.VideoCapture(str(INPUT_VIDEO))\n",
    "if not cap.isOpened():\n",
    "    raise SystemExit(\"Failed to open video: \" + str(INPUT_VIDEO))\n",
    "W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)); H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "FPS = cap.get(cv2.CAP_PROP_FPS) or 25.0\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"avc1\")  # use H.264 (avc1) for better Windows compatibility\n",
    "out = cv2.VideoWriter(str(OUTPUT_VIDEO), fourcc, FPS, (W, H))\n",
    "\n",
    "# color palette\n",
    "rng = np.random.RandomState(2)\n",
    "_palette_np = (rng.randint(0,255,(256,3))).astype(np.int32)\n",
    "PALETTE = [ (int(c[0]), int(c[1]), int(c[2])) for c in _palette_np ]\n",
    "\n",
    "# bookkeeping\n",
    "last_centroid = {}   # tid -> (cx, cy, t)\n",
    "csv_rows = []\n",
    "frame_id = 0\n",
    "t_start = time.time()\n",
    "\n",
    "print(\"Running calibrated tracker -> KM/H overlay. This may take some minutes depending on GPU/CPU.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame_bgr = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    t_frame = time.time()\n",
    "    frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # 1) optional segmentation (fast enough on gpu; skip if you prefer)\n",
    "    seg_mask = None\n",
    "    if seg_model is not None:\n",
    "        try:\n",
    "            rseg = seg_model.predict(frame_rgb, device=DEVICE, imgsz=640, verbose=False)[0]\n",
    "            if hasattr(rseg, \"masks\") and rseg.masks is not None:\n",
    "                arr = np.array(rseg.masks.data if hasattr(rseg.masks, \"data\") else rseg.masks.numpy())\n",
    "                seg_mask = np.argmax(arr, axis=0).astype(np.int32) if arr.ndim==3 else arr.astype(np.int32)\n",
    "        except Exception:\n",
    "            seg_mask = None\n",
    "\n",
    "    # 2) detection -> list of ([x1,y1,x2,y2], score, class_name)\n",
    "    detections_for_tracker = []\n",
    "    try:\n",
    "        r = det_model.predict(frame_rgb, device=DEVICE, imgsz=640, conf=CONF_THRESH, verbose=False)[0]\n",
    "        if hasattr(r, \"boxes\") and r.boxes is not None:\n",
    "            xyxy = r.boxes.xyxy.cpu().numpy() if hasattr(r.boxes, \"xyxy\") else np.array(r.boxes.xyxy)\n",
    "            confs = r.boxes.conf.cpu().numpy() if hasattr(r.boxes, \"conf\") else np.array(r.boxes.conf)\n",
    "            clsids = r.boxes.cls.cpu().numpy() if hasattr(r.boxes, \"cls\") else np.array(r.boxes.cls)\n",
    "            for (x1,y1,x2,y2), conf, clsid in zip(xyxy, confs, clsids):\n",
    "                detections_for_tracker.append(([float(x1), float(y1), float(x2), float(y2)], float(conf), str(int(clsid))))\n",
    "    except Exception as ex:\n",
    "        print(\"Detection warning:\", ex, file=sys.stderr)\n",
    "        detections_for_tracker = []\n",
    "\n",
    "    # 3) update tracker\n",
    "    tracks = tracker.update_tracks(detections_for_tracker, frame=frame_bgr)\n",
    "\n",
    "    # 4) draw tracked boxes + compute speed (km/h) and record CSV rows\n",
    "    for tr in tracks:\n",
    "        try:\n",
    "            if hasattr(tr, \"is_confirmed\") and (not tr.is_confirmed()):\n",
    "                continue\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # normalize track id to int\n",
    "        try:\n",
    "            tid = int(tr.track_id)\n",
    "        except Exception:\n",
    "            tid = abs(hash(str(tr.track_id))) % 10000\n",
    "\n",
    "        # bbox\n",
    "        try:\n",
    "            ltrb = tr.to_ltrb()\n",
    "        except Exception:\n",
    "            ltrb = tr.to_tlbr()\n",
    "        x1,y1,x2,y2 = map(int, ltrb)\n",
    "        cx = (x1 + x2) / 2.0\n",
    "        cy = (y1 + y2) / 2.0\n",
    "\n",
    "        # compute pixel speed and convert to km/h\n",
    "        speed_px_s = 0.0\n",
    "        speed_m_s = 0.0\n",
    "        speed_kmh = 0.0\n",
    "        if tid in last_centroid:\n",
    "            px, py, t_prev = last_centroid[tid]\n",
    "            dt = max(1e-6, t_frame - t_prev)\n",
    "            dist_px = math.hypot(cx - px, cy - py)\n",
    "            speed_px_s = dist_px / dt\n",
    "            speed_m_s = (dist_px / PX_PER_M) / dt\n",
    "            speed_kmh = speed_m_s * 3.6\n",
    "        last_centroid[tid] = (cx, cy, t_frame)\n",
    "\n",
    "        # draw bbox + label\n",
    "        color = PALETTE[tid % len(PALETTE)]\n",
    "        cv2.rectangle(frame_bgr, (x1,y1), (x2,y2), color, 2)\n",
    "        label = f\"ID:{tid} {speed_kmh:.1f} km/h\"\n",
    "        (tw, th), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "        bx1, by1 = x1, max(0, y1 - th - 6)\n",
    "        bx2, by2 = x1 + tw + 6, by1 + th + 6\n",
    "        cv2.rectangle(frame_bgr, (bx1, by1), (bx2, by2), color, -1)\n",
    "        cv2.putText(frame_bgr, label, (x1+3, by2-4), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "        # append CSV row\n",
    "        csv_rows.append({\n",
    "            \"frame\": frame_id,\n",
    "            \"time\": t_frame - t_start,\n",
    "            \"track_id\": tid,\n",
    "            \"x1\": x1, \"y1\": y1, \"x2\": x2, \"y2\": y2,\n",
    "            \"cx\": cx, \"cy\": cy,\n",
    "            \"speed_px_s\": speed_px_s,\n",
    "            \"speed_m_s\": speed_m_s,\n",
    "            \"speed_kmh\": speed_kmh\n",
    "        })\n",
    "\n",
    "    # 5) overlay segmentation if present\n",
    "    frame_out = frame_bgr\n",
    "    if seg_mask is not None:\n",
    "        if seg_mask.shape[:2] != (H, W):\n",
    "            seg_mask = cv2.resize(seg_mask.astype(np.int32), (W, H), interpolation=cv2.INTER_NEAREST)\n",
    "        seg_col = (np.random.RandomState(0).randint(0,255,(256,3))).astype(np.uint8)\n",
    "        color_mask = seg_col[np.mod(seg_mask.astype(np.int32),256)]\n",
    "        frame_out = (0.4 * frame_bgr.astype(np.float32) + 0.6 * color_mask.astype(np.float32)).astype(np.uint8)\n",
    "\n",
    "    out.write(frame_out)\n",
    "    frame_id += 1\n",
    "\n",
    "# finalize\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "# save CSV\n",
    "keys = [\"frame\",\"time\",\"track_id\",\"x1\",\"y1\",\"x2\",\"y2\",\"cx\",\"cy\",\"speed_px_s\",\"speed_m_s\",\"speed_kmh\"]\n",
    "with open(TRACKS_CSV, \"w\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=keys)\n",
    "    writer.writeheader()\n",
    "    for r in csv_rows:\n",
    "        writer.writerow({k: r.get(k, 0) for k in keys})\n",
    "\n",
    "t_end = time.time()\n",
    "print(\"Done. Saved video:\", OUTPUT_VIDEO)\n",
    "print(\"Saved CSV:\", TRACKS_CSV)\n",
    "print(f\"Frames: {frame_id}, Total time: {t_end - t_start:.1f}s, Achieved FPS: {frame_id / max(1, (t_end - t_start)):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "827c3135-4ef3-442c-a5e0-31ecfb3eec94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5468 track rows across 868 frames.\n",
      "Processing video and computing TTC...\n",
      "Done.\n",
      "Saved TTC video: C:\\Users\\Dell\\projects\\idas_lite_seg\\run_yolov8n_seg2\\output_riding_bike_ttc.mp4\n",
      "Saved TTC CSV : C:\\Users\\Dell\\projects\\idas_lite_seg\\run_yolov8n_seg2\\tracks_kmh_final_with_ttc.csv\n",
      "Frames: 870, Total time: 44.1s, Achieved FPS: 19.73\n",
      "Alarms triggered for tracks: [1, 4, 10, 14, 15, 19, 18, 28, 33, 37, 32, 48, 54, 65, 72, 71, 79, 67, 81, 80, 90, 86, 97, 100, 105, 109, 118, 119, 122, 123, 132, 129, 130, 145, 152, 158, 144, 171, 178, 182, 186, 189, 193, 194, 197, 204, 212, 216, 219, 220, 230, 234, 238, 239, 244, 245, 246, 248, 253, 259, 270, 274, 272, 284, 288, 290, 291, 294, 305, 307, 309, 312]\n"
     ]
    }
   ],
   "source": [
    "# Relative-TTC overlay (pixels) + optional audible beep\n",
    "# Kernel: Python (adas)\n",
    "\n",
    "from pathlib import Path\n",
    "import cv2, time, csv, math, numpy as np, sys\n",
    "import collections\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "VIDEO_PATH = Path(r\"E:/projects/riding_bike.mp4\")\n",
    "TRACKS_CSV = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/tracks_kmh_final.csv\")  # input CSV\n",
    "OUT_VIDEO  = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/output_riding_bike_ttc.mp4\")\n",
    "OUT_CSV    = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/tracks_kmh_final_with_ttc.csv\")\n",
    "\n",
    "TTC_THRESHOLD = 3.0     # seconds -> alarm when TTC < threshold\n",
    "BEEP_ON_ALARM = True    # Windows only (uses winsound). Set False to disable sound.\n",
    "ALARM_COOLDOWN = 2.0    # seconds between beeps per tracked object\n",
    "\n",
    "# ---------- Sanity ----------\n",
    "if not VIDEO_PATH.exists():\n",
    "    raise SystemExit(\"Video not found: \" + str(VIDEO_PATH))\n",
    "if not TRACKS_CSV.exists():\n",
    "    raise SystemExit(\"CSV not found: \" + str(TRACKS_CSV))\n",
    "\n",
    "# ---------- Load CSV into frame-indexed structure ----------\n",
    "frame_index = collections.defaultdict(list)\n",
    "all_rows = []\n",
    "with open(TRACKS_CSV, newline='') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for r in reader:\n",
    "        # convert numeric fields\n",
    "        r2 = dict(r)\n",
    "        r2['frame'] = int(float(r['frame']))\n",
    "        r2['track_id'] = int(float(r['track_id']))\n",
    "        r2['x1'] = int(float(r['x1'])); r2['y1'] = int(float(r['y1']))\n",
    "        r2['x2'] = int(float(r['x2'])); r2['y2'] = int(float(r['y2']))\n",
    "        r2['speed_px_s'] = float(r.get('speed_px_s', 0.0))\n",
    "        frame_index[r2['frame']].append(r2)\n",
    "        all_rows.append(r2)\n",
    "\n",
    "print(f\"Loaded {len(all_rows)} track rows across {len(frame_index)} frames.\")\n",
    "\n",
    "# ---------- Video IO setup ----------\n",
    "cap = cv2.VideoCapture(str(VIDEO_PATH))\n",
    "if not cap.isOpened():\n",
    "    raise SystemExit(\"Failed to open video: \" + str(VIDEO_PATH))\n",
    "W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)); H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "FPS = cap.get(cv2.CAP_PROP_FPS) or 25.0\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"avc1\")   # H.264 (Windows friendly)\n",
    "out = cv2.VideoWriter(str(OUT_VIDEO), fourcc, FPS, (W, H))\n",
    "\n",
    "# color palette\n",
    "rng = np.random.RandomState(7)\n",
    "palette = (rng.randint(0,255,(256,3))).astype(np.int32)\n",
    "PALETTE = [ (int(c[0]), int(c[1]), int(c[2])) for c in palette ]\n",
    "\n",
    "# alarm state per track\n",
    "last_alarm_time = {}   # track_id -> last alarm timestamp\n",
    "\n",
    "# output CSV writer setup (we will append ttc + alarm)\n",
    "out_rows = []\n",
    "keys = None\n",
    "\n",
    "frame_id = 0\n",
    "t_start = time.time()\n",
    "print(\"Processing video and computing TTC...\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # find rows for this frame\n",
    "    rows = frame_index.get(frame_id, [])\n",
    "\n",
    "    # for each detection compute TTC\n",
    "    for r in rows:\n",
    "        tid = r['track_id']\n",
    "        x1,y1,x2,y2 = r['x1'], r['y1'], r['x2'], r['y2']\n",
    "        speed_px_s = r.get('speed_px_s', 0.0)\n",
    "\n",
    "        # estimate distance in pixels (vertical distance from box bottom to bottom of image)\n",
    "        dist_px = max(0.0, (H - y2))\n",
    "\n",
    "        # compute TTC in seconds (handle very small speeds)\n",
    "        if speed_px_s > 1e-3:\n",
    "            ttc = dist_px / speed_px_s\n",
    "        else:\n",
    "            ttc = float('inf')\n",
    "\n",
    "        alarm = False\n",
    "        now = time.time()\n",
    "        if ttc != float('inf') and ttc <= TTC_THRESHOLD:\n",
    "            # check cooldown so we don't beep every frame for same object\n",
    "            last = last_alarm_time.get(tid, -9999)\n",
    "            if (now - last) >= ALARM_COOLDOWN:\n",
    "                alarm = True\n",
    "                last_alarm_time[tid] = now\n",
    "                # beep (Windows)\n",
    "                if BEEP_ON_ALARM:\n",
    "                    try:\n",
    "                        import winsound\n",
    "                        # short beep 600Hz for 180ms\n",
    "                        winsound.Beep(600, 180)\n",
    "                    except Exception:\n",
    "                        # not Windows or winsound unavailable — ignore\n",
    "                        pass\n",
    "\n",
    "        # draw overlays on frame\n",
    "        color = PALETTE[tid % len(PALETTE)]\n",
    "        if alarm:\n",
    "            box_color = (0,0,255)   # red for alarm\n",
    "        else:\n",
    "            box_color = color\n",
    "        cv2.rectangle(frame, (x1,y1), (x2,y2), box_color, 2)\n",
    "\n",
    "        # label: ID + TTC or 'inf'\n",
    "        label = f\"ID:{tid} \"\n",
    "        if ttc == float('inf'):\n",
    "            label += \"TTC: inf\"\n",
    "        else:\n",
    "            label += f\"TTC: {ttc:.1f}s\"\n",
    "            if alarm:\n",
    "                label += \" !!\"\n",
    "\n",
    "        (tw, th), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "        bx1, by1 = x1, max(0, y1 - th - 6)\n",
    "        bx2, by2 = x1 + tw + 6, by1 + th + 6\n",
    "        cv2.rectangle(frame, (bx1, by1), (bx2, by2), box_color, -1)\n",
    "        cv2.putText(frame, label, (x1+3, by2-4), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "        # store output row\n",
    "        out_row = dict(r)\n",
    "        out_row['ttc_s'] = ttc\n",
    "        out_row['alarm'] = int(alarm)\n",
    "        out_rows.append(out_row)\n",
    "        if keys is None:\n",
    "            keys = list(out_row.keys())\n",
    "\n",
    "    out.write(frame)\n",
    "    frame_id += 1\n",
    "\n",
    "# finish\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "# save CSV\n",
    "if keys is None:\n",
    "    keys = [\"frame\",\"track_id\",\"x1\",\"y1\",\"x2\",\"y2\",\"speed_px_s\",\"ttc_s\",\"alarm\"]\n",
    "with open(OUT_CSV, \"w\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=keys)\n",
    "    writer.writeheader()\n",
    "    for r in out_rows:\n",
    "        writer.writerow(r)\n",
    "\n",
    "t_end = time.time()\n",
    "print(\"Done.\")\n",
    "print(\"Saved TTC video:\", OUT_VIDEO)\n",
    "print(\"Saved TTC CSV :\", OUT_CSV)\n",
    "print(f\"Frames: {frame_id}, Total time: {t_end - t_start:.1f}s, Achieved FPS: {frame_id / max(1, (t_end - t_start)):.2f}\")\n",
    "print(f\"Alarms triggered for tracks: {list(last_alarm_time.keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e3385ae-b4c5-4bed-a80d-70bcf8ff56dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5468 rows for 868 frames.\n",
      "Running refined TTC confirmation...\n",
      "Done.\n",
      "Saved refined TTC video to: C:\\Users\\Dell\\projects\\idas_lite_seg\\run_yolov8n_seg2\\output_riding_bike_ttc_confirmed.mp4\n",
      "Saved refined TTC CSV to: C:\\Users\\Dell\\projects\\idas_lite_seg\\run_yolov8n_seg2\\tracks_kmh_ttc_confirmed.csv\n",
      "Frames: 870, Total time: 27.2s, Achieved FPS: 31.93\n"
     ]
    }
   ],
   "source": [
    "# TTC refinement: smoothing + consecutive-frame confirmation + min box size filter\n",
    "# Kernel: Python (adas)\n",
    "\n",
    "from pathlib import Path\n",
    "import csv, time, math, collections, numpy as np, cv2, winsound, sys\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "VIDEO_PATH = Path(r\"E:/projects/riding_bike.mp4\")\n",
    "IN_CSV = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/tracks_kmh_final.csv\")  # input you created earlier\n",
    "OUT_VIDEO = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/output_riding_bike_ttc_confirmed.mp4\")\n",
    "OUT_CSV   = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/tracks_kmh_ttc_confirmed.csv\")\n",
    "\n",
    "TTC_THRESHOLD = 3.0          # seconds (same as before)\n",
    "MIN_CONSECUTIVE = 3          # require TTC below threshold for this many frames to confirm alarm\n",
    "SMOOTH_WINDOW = 3            # moving average window (in frames) for speed_px_s\n",
    "MIN_BOX_AREA = 400           # ignore detections with bbox area < this (pixels^2)\n",
    "ALARM_COOLDOWN = 2.0         # seconds between beeps per track\n",
    "BEEP_ON_ALARM = True         # True to play beep (Windows)\n",
    "\n",
    "# ---------- load CSV into frame-index structure ----------\n",
    "if not IN_CSV.exists():\n",
    "    raise SystemExit(f\"Input CSV not found: {IN_CSV}\")\n",
    "\n",
    "frame_index = collections.defaultdict(list)\n",
    "all_rows = []\n",
    "with open(IN_CSV, newline='') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for r in reader:\n",
    "        fr = int(float(r['frame']))\n",
    "        tid = int(float(r['track_id']))\n",
    "        x1 = int(float(r['x1'])); y1 = int(float(r['y1']))\n",
    "        x2 = int(float(r['x2'])); y2 = int(float(r['y2']))\n",
    "        sp = float(r.get('speed_px_s', 0.0))\n",
    "        entry = {\"frame\": fr, \"track_id\": tid, \"x1\": x1, \"y1\": y1, \"x2\": x2, \"y2\": y2, \"speed_px_s\": sp}\n",
    "        frame_index[fr].append(entry)\n",
    "        all_rows.append(entry)\n",
    "\n",
    "print(f\"Loaded {len(all_rows)} rows for {len(frame_index)} frames.\")\n",
    "\n",
    "# ---------- Build per-track time-ordered lists ----------\n",
    "tracks = collections.defaultdict(list)\n",
    "for r in all_rows:\n",
    "    tracks[r['track_id']].append((r['frame'], r['speed_px_s'], r['x1'], r['y1'], r['x2'], r['y2']))\n",
    "\n",
    "# sort and compute smoothed speed per frame per track\n",
    "smoothed = collections.defaultdict(dict)  # smoothed[track_id][frame] = smoothed_speed_px_s\n",
    "for tid, triplets in tracks.items():\n",
    "    triplets_sorted = sorted(triplets, key=lambda x: x[0])\n",
    "    speeds = [t[1] for t in triplets_sorted]\n",
    "    frames = [t[0] for t in triplets_sorted]\n",
    "    # moving average\n",
    "    k = SMOOTH_WINDOW\n",
    "    if k <= 1:\n",
    "        sm = speeds\n",
    "    else:\n",
    "        sm = np.convolve(speeds, np.ones(k)/k, mode='same')\n",
    "    for f, s in zip(frames, sm):\n",
    "        smoothed[tid][f] = float(s)\n",
    "\n",
    "# ---------- iterate video, compute TTC with smoothed speeds and confirm alarms ----------\n",
    "cap = cv2.VideoCapture(str(VIDEO_PATH))\n",
    "if not cap.isOpened():\n",
    "    raise SystemExit(\"Failed to open video.\")\n",
    "W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)); H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "FPS = cap.get(cv2.CAP_PROP_FPS) or 25.0\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"avc1\")\n",
    "out = cv2.VideoWriter(str(OUT_VIDEO), fourcc, FPS, (W, H))\n",
    "\n",
    "# per-track state for consecutive below-threshold\n",
    "consec_below = collections.defaultdict(int)    # tid -> count\n",
    "confirmed_alarm_state = collections.defaultdict(bool)  # tid -> True if currently alarmed (persist until reset)\n",
    "last_alarm_time = collections.defaultdict(lambda: -9999)\n",
    "rows_out = []\n",
    "\n",
    "frame_id = 0\n",
    "t0 = time.time()\n",
    "print(\"Running refined TTC confirmation...\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    rows = frame_index.get(frame_id, [])\n",
    "    for r in rows:\n",
    "        tid = r['track_id']\n",
    "        x1,y1,x2,y2 = r['x1'], r['y1'], r['x2'], r['y2']\n",
    "        w = max(0, x2 - x1); h = max(0, y2 - y1)\n",
    "        area = w * h\n",
    "        if area < MIN_BOX_AREA:\n",
    "            # ignore small boxes\n",
    "            ttc = float('inf')\n",
    "            alarm = 0\n",
    "            consec_below[tid] = 0\n",
    "        else:\n",
    "            sp = smoothed.get(tid, {}).get(frame_id, r['speed_px_s'])\n",
    "            dist_px = max(0.0, (H - y2))\n",
    "            ttc = dist_px / sp if sp > 1e-3 else float('inf')\n",
    "            if ttc <= TTC_THRESHOLD:\n",
    "                consec_below[tid] += 1\n",
    "            else:\n",
    "                consec_below[tid] = 0\n",
    "\n",
    "            if consec_below[tid] >= MIN_CONSECUTIVE and not confirmed_alarm_state.get(tid, False):\n",
    "                # confirm new alarm\n",
    "                confirmed_alarm_state[tid] = True\n",
    "                alarm = 1\n",
    "                now = time.time()\n",
    "                last_alarm_time[tid] = now\n",
    "                if BEEP_ON_ALARM:\n",
    "                    try:\n",
    "                        winsound.Beep(700, 180)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            elif confirmed_alarm_state.get(tid, False):\n",
    "                # keep alarmed until TTC rises above threshold for MIN_CONSECUTIVE frames\n",
    "                if ttc > TTC_THRESHOLD:\n",
    "                    # count up a \"clear\" counter by reusing consec_below as negative counter\n",
    "                    consec_below[tid] = 0\n",
    "                    confirmed_alarm_state[tid] = False\n",
    "                    alarm = 0\n",
    "                else:\n",
    "                    alarm = 1\n",
    "            else:\n",
    "                alarm = 0\n",
    "\n",
    "        # draw box\n",
    "        color = (0,0,255) if alarm else (int(100), int(220), int(100))\n",
    "        cv2.rectangle(frame, (x1,y1), (x2,y2), color, 2)\n",
    "        label = f\"ID:{tid} TTC:{(ttc if ttc!=float('inf') else 9999):.1f}s\"\n",
    "        if alarm:\n",
    "            label += \" !!\"\n",
    "        (tw, th), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "        bx1, by1 = x1, max(0, y1 - th - 6)\n",
    "        bx2, by2 = x1 + tw + 6, by1 + th + 6\n",
    "        cv2.rectangle(frame, (bx1, by1), (bx2, by2), color, -1)\n",
    "        cv2.putText(frame, label, (x1+3, by2-4), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "        out_row = dict(r)\n",
    "        out_row['ttc_s'] = ttc\n",
    "        out_row['alarm_confirmed'] = int(alarm)\n",
    "        rows_out.append(out_row)\n",
    "\n",
    "    out.write(frame)\n",
    "    frame_id += 1\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "# save CSV\n",
    "keys = [\"frame\",\"track_id\",\"x1\",\"y1\",\"x2\",\"y2\",\"speed_px_s\",\"ttc_s\",\"alarm_confirmed\"]\n",
    "with open(OUT_CSV, \"w\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=keys)\n",
    "    writer.writeheader()\n",
    "    for r in rows_out:\n",
    "        writer.writerow({k: r.get(k, 0) for k in keys})\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"Done.\")\n",
    "print(\"Saved refined TTC video to:\", OUT_VIDEO)\n",
    "print(\"Saved refined TTC CSV to:\", OUT_CSV)\n",
    "print(f\"Frames: {frame_id}, Total time: {t1 - t0:.1f}s, Achieved FPS: {frame_id / max(1, (t1 - t0)):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0bae851-5190-495e-b8a4-a49cf90d4b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved lane detection with dynamic bike-hood exclusion (test cell)\n",
    "# Kernel: Python (adas)\n",
    "import cv2, numpy as np, math\n",
    "from pathlib import Path\n",
    "\n",
    "VIDEO_PATH = Path(r\"E:/projects/riding_bike.mp4\")\n",
    "\n",
    "def refined_lane_detection_v2(frame, seg_mask=None,\n",
    "                               roi_top_frac=0.62,\n",
    "                               center_search_w_frac=0.5,   # width fraction to search for hood\n",
    "                               center_search_h_frac=0.45,  # height frac from bottom to search\n",
    "                               dark_thresh=90,             # gray threshold to call \"dark\" pixels\n",
    "                               min_dark_area=2000,         # min area to consider as bike hood\n",
    "                               canny_low=50, canny_high=150,\n",
    "                               hough_rho=1, hough_theta=np.pi/180, hough_thresh=30,\n",
    "                               min_line_length=40, max_line_gap=20,\n",
    "                               slope_thresh_min=0.35):\n",
    "    \"\"\"\n",
    "    Returns left_line, right_line, lane_center, debug dict\n",
    "    Each line is (x1,y1,x2,y2) or None. debug contains images to visualize.\n",
    "    \"\"\"\n",
    "    H, W = frame.shape[:2]\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "\n",
    "    # ROI lower part\n",
    "    top_y = int(H * roi_top_frac)\n",
    "    mask_roi = np.zeros_like(gray)\n",
    "    poly = np.array([[(0,H),(0,top_y),(W,top_y),(W,H)]], dtype=np.int32)\n",
    "    cv2.fillPoly(mask_roi, poly, 255)\n",
    "\n",
    "    # detect dark large region inside center-bottom search window (bike hood / hands)\n",
    "    sw = int(W * center_search_w_frac)\n",
    "    sh = int(H * center_search_h_frac)\n",
    "    sx1 = max(0, (W - sw)//2)\n",
    "    sx2 = min(W, sx1 + sw)\n",
    "    sy1 = max(top_y, H - sh)   # search lower portion only\n",
    "    sy2 = H\n",
    "    search_patch = gray[sy1:sy2, sx1:sx2]\n",
    "    # threshold dark pixels\n",
    "    _, dark_mask = cv2.threshold(search_patch, dark_thresh, 255, cv2.THRESH_BINARY_INV)\n",
    "    # morphological close to combine regions\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15,15))\n",
    "    dark_mask = cv2.morphologyEx(dark_mask, cv2.MORPH_CLOSE, kernel)\n",
    "    # find contours and pick largest by area\n",
    "    cnts, _ = cv2.findContours(dark_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    ex_mask = np.zeros_like(gray)\n",
    "    hood_box = None\n",
    "    if cnts:\n",
    "        cnts = sorted(cnts, key=lambda c: cv2.contourArea(c), reverse=True)\n",
    "        for c in cnts:\n",
    "            area = cv2.contourArea(c)\n",
    "            if area < min_dark_area:\n",
    "                continue\n",
    "            # bounding box in search_patch coords -> convert to full frame coords\n",
    "            x,y,w,h = cv2.boundingRect(c)\n",
    "            X1, Y1 = sx1 + x, sy1 + y\n",
    "            X2, Y2 = X1 + w, Y1 + h\n",
    "            # expand a bit\n",
    "            pad_x = int(0.06 * W)\n",
    "            pad_y = int(0.06 * H)\n",
    "            X1 = max(0, X1 - pad_x); Y1 = max(0, Y1 - pad_y)\n",
    "            X2 = min(W, X2 + pad_x); Y2 = min(H, Y2 + pad_y)\n",
    "            hood_box = (X1, Y1, X2, Y2)\n",
    "            cv2.rectangle(ex_mask, (X1, Y1), (X2, Y2), 255, -1)\n",
    "            break\n",
    "\n",
    "    # edges from Canny inside ROI\n",
    "    edges = cv2.Canny(blur, canny_low, canny_high)\n",
    "    edges_roi = cv2.bitwise_and(edges, mask_roi)\n",
    "    # apply segmentation mask if available (assumes road>0)\n",
    "    if seg_mask is not None:\n",
    "        try:\n",
    "            road_mask = (seg_mask > 0).astype(np.uint8) * 255\n",
    "            edges_roi = cv2.bitwise_and(edges_roi, road_mask)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # zero out found hood region (exclude it)\n",
    "    if hood_box is not None:\n",
    "        X1, Y1, X2, Y2 = hood_box\n",
    "        edges_roi[Y1:Y2, X1:X2] = 0\n",
    "\n",
    "    # small morphological closing to reduce noise\n",
    "    ker2 = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "    edges_roi = cv2.morphologyEx(edges_roi, cv2.MORPH_CLOSE, ker2)\n",
    "\n",
    "    # Hough\n",
    "    raw = cv2.HoughLinesP(edges_roi, hough_rho, hough_theta, hough_thresh,\n",
    "                          minLineLength=min_line_length, maxLineGap=max_line_gap)\n",
    "    candidates = []\n",
    "    if raw is not None:\n",
    "        for l in raw:\n",
    "            x1,y1,x2,y2 = l[0]\n",
    "            if x2 == x1:\n",
    "                slope = float('inf')\n",
    "            else:\n",
    "                slope = (y2-y1)/(x2-x1)\n",
    "            if abs(slope) < slope_thresh_min:\n",
    "                continue\n",
    "            # discard lines mostly inside hood_box area\n",
    "            if hood_box is not None:\n",
    "                hx1, hy1, hx2, hy2 = hood_box\n",
    "                midx = (x1+x2)//2; midy = (y1+y2)//2\n",
    "                if hx1 <= midx <= hx2 and hy1 <= midy <= hy2:\n",
    "                    continue\n",
    "            candidates.append((x1,y1,x2,y2,slope))\n",
    "\n",
    "    # split to left / right\n",
    "    left_lines = [ (x1,y1,x2,y2) for (x1,y1,x2,y2,s) in candidates if s < 0 ]\n",
    "    right_lines = [ (x1,y1,x2,y2) for (x1,y1,x2,y2,s) in candidates if s > 0 ]\n",
    "\n",
    "    def aggregate(group):\n",
    "        if not group:\n",
    "            return None\n",
    "        xs1 = np.array([g[0] for g in group]); ys1 = np.array([g[1] for g in group])\n",
    "        xs2 = np.array([g[2] for g in group]); ys2 = np.array([g[3] for g in group])\n",
    "        return (int(np.median(xs1)), int(np.median(ys1)), int(np.median(xs2)), int(np.median(ys2)))\n",
    "\n",
    "    left = aggregate(left_lines)\n",
    "    right = aggregate(right_lines)\n",
    "    # lane center\n",
    "    if left is None and right is None:\n",
    "        lane_center = None\n",
    "    elif left is None:\n",
    "        lx1,ly1,lx2,ly2 = right\n",
    "        lane_center = ((lx1 - W//4, ly1), (lx2 - W//4, ly2))\n",
    "    elif right is None:\n",
    "        rx1,ry1,rx2,ry2 = left\n",
    "        lane_center = ((rx1 + W//4, ry1), (rx2 + W//4, ry2))\n",
    "    else:\n",
    "        lx1,ly1,lx2,ly2 = left; rx1,ry1,rx2,ry2 = right\n",
    "        lane_center = ((int((lx1+rx1)/2), int((ly1+ry1)/2)), (int((lx2+rx2)/2), int((ly2+ry2)/2)))\n",
    "\n",
    "    debug = {\n",
    "        \"edges_roi\": edges_roi,\n",
    "        \"hood_box\": hood_box,\n",
    "        \"raw_candidates\": candidates,\n",
    "        \"left_lines\": left_lines,\n",
    "        \"right_lines\": right_lines\n",
    "    }\n",
    "    return left, right, lane_center, debug\n",
    "\n",
    "# ---------------- single-frame test & visualization ----------------\n",
    "cap = cv2.VideoCapture(str(VIDEO_PATH))\n",
    "ret, frame0 = cap.read()\n",
    "cap.release()\n",
    "if not ret:\n",
    "    raise SystemExit(\"Cannot read video frame for test.\")\n",
    "\n",
    "left, right, center, debug = refined_lane_detection_v2(frame0, seg_mask=None)\n",
    "\n",
    "vis = frame0.copy()\n",
    "# visualize hood box (if any)\n",
    "if debug.get(\"hood_box\") is not None:\n",
    "    x1,y1,x2,y2 = debug[\"hood_box\"]\n",
    "    cv2.rectangle(vis, (x1,y1), (x2,y2), (0,0,255), 2)\n",
    "# visualize edges\n",
    "edges_bgr = cv2.cvtColor(debug[\"edges_roi\"], cv2.COLOR_GRAY2BGR)\n",
    "# draw candidate raw lines in yellow\n",
    "for (x1,y1,x2,y2,s) in debug[\"raw_candidates\"]:\n",
    "    cv2.line(vis, (x1,y1), (x2,y2), (0,255,255), 1)\n",
    "# draw aggregated left/right/center\n",
    "if left is not None:\n",
    "    cv2.line(vis, (left[0],left[1]), (left[2],left[3]), (0,255,0), 3)\n",
    "if right is not None:\n",
    "    cv2.line(vis, (right[0],right[1]), (right[2],right[3]), (0,255,0), 3)\n",
    "if center is not None:\n",
    "    (c1,c2) = center\n",
    "    cv2.line(vis, (c1[0],c1[1]), (c2[0],c2[1]), (255,0,0), 3)\n",
    "\n",
    "# show combined visualization side-by-side with edges\n",
    "combined = np.hstack([cv2.resize(vis, (vis.shape[1]//1, vis.shape[0]//1)), cv2.resize(edges_bgr, (vis.shape[1]//1, vis.shape[0]//1))])\n",
    "# If running in notebook, use cv2.imshow; otherwise save to file\n",
    "try:\n",
    "    cv2.imshow(\"lane test (L) + edges (R). Press any key to close\", combined)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "except Exception:\n",
    "    outp = Path(\"lane_test_debug.png\")\n",
    "    cv2.imwrite(str(outp), combined)\n",
    "    print(\"Saved debug image to:\", outp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61eb6eb8-f06e-4d88-b44c-610aedc8c7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n",
      "Segmentation model loaded.\n",
      "Using pixel-speed CSV for data: C:\\Users\\Dell\\projects\\idas_lite_seg\\run_yolov8n_seg2\\tracks_kmh_final.csv\n",
      "Starting refined ADAS processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_5308\\4131381709.py:228: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  arr = np.array(rseg.masks.data if hasattr(rseg.masks, \"data\") else rseg.masks.numpy())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE.\n",
      "Refined ADAS video saved to: C:\\Users\\Dell\\projects\\idas_lite_seg\\run_yolov8n_seg2\\output_riding_bike_adas_refined.mp4\n",
      "Events CSV saved to: C:\\Users\\Dell\\projects\\idas_lite_seg\\run_yolov8n_seg2\\adas_events_refined.csv\n"
     ]
    }
   ],
   "source": [
    "# Final ADAS pipeline with robust lane detection (dynamic hood exclusion)\n",
    "# Kernel: Python (adas)\n",
    "# Outputs:\n",
    "#   - annotated video: output_riding_bike_adas_refined.mp4\n",
    "#   - events CSV: adas_events_refined.csv\n",
    "\n",
    "from pathlib import Path\n",
    "import cv2, time, math, csv, numpy as np, collections, sys\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "VIDEO_PATH = Path(r\"E:/projects/riding_bike.mp4\")\n",
    "OUTPUT_VIDEO = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/output_riding_bike_adas_refined.mp4\")\n",
    "EVENTS_CSV = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/adas_events_refined.csv\")\n",
    "\n",
    "DETECT_WEIGHTS = \"yolov8n.pt\"\n",
    "SEG_WEIGHTS = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/weights/best.pt\")  # optional\n",
    "TRACKS_CSV_HOMO = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/tracks_kmh_final_homography.csv\")\n",
    "TRACKS_CSV = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/tracks_kmh_final.csv\")\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "CONF_THRESH = 0.3\n",
    "\n",
    "# lane detection / hood detection params (tweak if needed)\n",
    "ROI_TOP_FRAC = 0.62\n",
    "CENTER_SEARCH_W_FRAC = 0.5\n",
    "CENTER_SEARCH_H_FRAC = 0.45\n",
    "DARK_THRESH = 90\n",
    "MIN_DARK_AREA = 2000\n",
    "CANNY_LOW = 50\n",
    "CANNY_HIGH = 150\n",
    "HOUGH_THRESH = 30\n",
    "MIN_LINE_LENGTH = 40\n",
    "MAX_LINE_GAP = 20\n",
    "SLOPE_MIN = 0.35\n",
    "\n",
    "# ADAS thresholds\n",
    "TTC_THRESHOLD = 3.0         # seconds\n",
    "DEPARTURE_THRESHOLD_PX = 60 # fallback pixels threshold for lane departure\n",
    "ALARM_COOLDOWN = 2.0\n",
    "BEEP_ON_ALARM = True        # set False if no sound desired\n",
    "\n",
    "# ---------------- sanity checks ----------------\n",
    "if not VIDEO_PATH.exists():\n",
    "    raise SystemExit(\"Input video not found: \" + str(VIDEO_PATH))\n",
    "\n",
    "# ---------------- lane detection helper (robust v2) ----------------\n",
    "def refined_lane_detection_v2(frame, seg_mask=None,\n",
    "                               roi_top_frac=ROI_TOP_FRAC,\n",
    "                               center_search_w_frac=CENTER_SEARCH_W_FRAC,\n",
    "                               center_search_h_frac=CENTER_SEARCH_H_FRAC,\n",
    "                               dark_thresh=DARK_THRESH,\n",
    "                               min_dark_area=MIN_DARK_AREA,\n",
    "                               canny_low=CANNY_LOW, canny_high=CANNY_HIGH,\n",
    "                               hough_rho=1, hough_theta=np.pi/180, hough_thresh=HOUGH_THRESH,\n",
    "                               min_line_length=MIN_LINE_LENGTH, max_line_gap=MAX_LINE_GAP,\n",
    "                               slope_thresh_min=SLOPE_MIN):\n",
    "    H, W = frame.shape[:2]\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "\n",
    "    top_y = int(H * roi_top_frac)\n",
    "    mask_roi = np.zeros_like(gray)\n",
    "    poly = np.array([[(0,H),(0,top_y),(W,top_y),(W,H)]], dtype=np.int32)\n",
    "    cv2.fillPoly(mask_roi, poly, 255)\n",
    "\n",
    "    # search for dark hood region in bottom-center patch\n",
    "    sw = int(W * center_search_w_frac)\n",
    "    sh = int(H * center_search_h_frac)\n",
    "    sx1 = max(0, (W - sw)//2)\n",
    "    sx2 = min(W, sx1 + sw)\n",
    "    sy1 = max(top_y, H - sh)\n",
    "    sy2 = H\n",
    "    search_patch = gray[sy1:sy2, sx1:sx2]\n",
    "    _, dark_mask = cv2.threshold(search_patch, dark_thresh, 255, cv2.THRESH_BINARY_INV)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15,15))\n",
    "    dark_mask = cv2.morphologyEx(dark_mask, cv2.MORPH_CLOSE, kernel)\n",
    "    cnts, _ = cv2.findContours(dark_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    ex_mask = np.zeros_like(gray)\n",
    "    hood_box = None\n",
    "    if cnts:\n",
    "        cnts = sorted(cnts, key=lambda c: cv2.contourArea(c), reverse=True)\n",
    "        for c in cnts:\n",
    "            area = cv2.contourArea(c)\n",
    "            if area < min_dark_area:\n",
    "                continue\n",
    "            x,y,w,h = cv2.boundingRect(c)\n",
    "            X1, Y1 = sx1 + x, sy1 + y\n",
    "            X2, Y2 = X1 + w, Y1 + h\n",
    "            pad_x = int(0.06 * W); pad_y = int(0.06 * H)\n",
    "            X1 = max(0, X1 - pad_x); Y1 = max(0, Y1 - pad_y)\n",
    "            X2 = min(W, X2 + pad_x); Y2 = min(H, Y2 + pad_y)\n",
    "            hood_box = (X1, Y1, X2, Y2)\n",
    "            cv2.rectangle(ex_mask, (X1, Y1), (X2, Y2), 255, -1)\n",
    "            break\n",
    "\n",
    "    # edges in ROI, optionally masked by seg_mask\n",
    "    edges = cv2.Canny(blur, canny_low, canny_high)\n",
    "    edges_roi = cv2.bitwise_and(edges, mask_roi)\n",
    "    if seg_mask is not None:\n",
    "        try:\n",
    "            road_mask = (seg_mask > 0).astype(np.uint8) * 255\n",
    "            edges_roi = cv2.bitwise_and(edges_roi, road_mask)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # exclude hood area\n",
    "    if hood_box is not None:\n",
    "        X1,Y1,X2,Y2 = hood_box\n",
    "        edges_roi[Y1:Y2, X1:X2] = 0\n",
    "\n",
    "    ker2 = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "    edges_roi = cv2.morphologyEx(edges_roi, cv2.MORPH_CLOSE, ker2)\n",
    "\n",
    "    raw = cv2.HoughLinesP(edges_roi, hough_rho, hough_theta, hough_thresh,\n",
    "                          minLineLength=min_line_length, maxLineGap=max_line_gap)\n",
    "    candidates = []\n",
    "    if raw is not None:\n",
    "        for l in raw:\n",
    "            x1,y1,x2,y2 = l[0]\n",
    "            if x2 == x1:\n",
    "                slope = float('inf')\n",
    "            else:\n",
    "                slope = (y2-y1)/(x2-x1)\n",
    "            if abs(slope) < slope_thresh_min:\n",
    "                continue\n",
    "            if hood_box is not None:\n",
    "                hx1,hy1,hx2,hy2 = hood_box\n",
    "                midx = (x1+x2)//2; midy = (y1+y2)//2\n",
    "                if hx1 <= midx <= hx2 and hy1 <= midy <= hy2:\n",
    "                    continue\n",
    "            candidates.append((x1,y1,x2,y2,slope))\n",
    "\n",
    "    left_lines = [ (x1,y1,x2,y2) for (x1,y1,x2,y2,s) in candidates if s < 0 ]\n",
    "    right_lines = [ (x1,y1,x2,y2) for (x1,y1,x2,y2,s) in candidates if s > 0 ]\n",
    "\n",
    "    def aggregate(group):\n",
    "        if not group:\n",
    "            return None\n",
    "        xs1 = np.array([g[0] for g in group]); ys1 = np.array([g[1] for g in group])\n",
    "        xs2 = np.array([g[2] for g in group]); ys2 = np.array([g[3] for g in group])\n",
    "        return (int(np.median(xs1)), int(np.median(ys1)), int(np.median(xs2)), int(np.median(ys2)))\n",
    "\n",
    "    left = aggregate(left_lines)\n",
    "    right = aggregate(right_lines)\n",
    "    if left is None and right is None:\n",
    "        lane_center = None\n",
    "    elif left is None:\n",
    "        lx1,ly1,lx2,ly2 = right\n",
    "        lane_center = ((lx1 - W//4, ly1), (lx2 - W//4, ly2))\n",
    "    elif right is None:\n",
    "        rx1,ry1,rx2,ry2 = left\n",
    "        lane_center = ((rx1 + W//4, ry1), (rx2 + W//4, ry2))\n",
    "    else:\n",
    "        lx1,ly1,lx2,ly2 = left; rx1,ry1,rx2,ry2 = right\n",
    "        lane_center = ((int((lx1+rx1)/2), int((ly1+ry1)/2)), (int((lx2+rx2)/2), int((ly2+ry2)/2)))\n",
    "\n",
    "    debug = {\"edges_roi\": edges_roi, \"hood_box\": hood_box, \"candidates\": candidates, \"left_lines\": left_lines, \"right_lines\": right_lines}\n",
    "    return left, right, lane_center, debug\n",
    "\n",
    "# ---------------- Load models & CSVs ----------------\n",
    "print(\"Loading models...\")\n",
    "det_model = YOLO(DETECT_WEIGHTS)\n",
    "seg_model = None\n",
    "if SEG_WEIGHTS is not None and SEG_WEIGHTS.exists():\n",
    "    seg_model = YOLO(str(SEG_WEIGHTS))\n",
    "    print(\"Segmentation model loaded.\")\n",
    "else:\n",
    "    print(\"Segmentation model not found - segmentation overlay disabled.\")\n",
    "\n",
    "use_homography = False\n",
    "homography_rows_by_frame = {}\n",
    "if TRACKS_CSV_HOMO.exists():\n",
    "    with open(TRACKS_CSV_HOMO, newline='') as f:\n",
    "        import csv\n",
    "        reader = csv.DictReader(f)\n",
    "        for r in reader:\n",
    "            fr = int(float(r['frame']))\n",
    "            homography_rows_by_frame.setdefault(fr, []).append(r)\n",
    "    use_homography = True\n",
    "    print(\"Using homography CSV for metric speeds/TTC:\", TRACKS_CSV_HOMO)\n",
    "elif TRACKS_CSV.exists():\n",
    "    with open(TRACKS_CSV, newline='') as f:\n",
    "        import csv\n",
    "        rows = [r for r in csv.DictReader(f)]\n",
    "    rows_by_frame = collections.defaultdict(list)\n",
    "    for r in rows:\n",
    "        rows_by_frame[int(float(r['frame']))].append(r)\n",
    "    print(\"Using pixel-speed CSV for data:\", TRACKS_CSV)\n",
    "else:\n",
    "    rows_by_frame = {}\n",
    "\n",
    "# ---------------- Video IO & tracker ----------------\n",
    "cap = cv2.VideoCapture(str(VIDEO_PATH))\n",
    "if not cap.isOpened():\n",
    "    raise SystemExit(\"Failed to open video.\")\n",
    "W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)); H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "FPS = cap.get(cv2.CAP_PROP_FPS) or 25.0\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"avc1\")\n",
    "out = cv2.VideoWriter(str(OUTPUT_VIDEO), fourcc, FPS, (W, H))\n",
    "tracker = DeepSort(max_age=30)\n",
    "\n",
    "palette = (np.random.RandomState(2).randint(0,255,(256,3))).astype(np.int32)\n",
    "PALETTE = [ (int(c[0]), int(c[1]), int(c[2])) for c in palette ]\n",
    "\n",
    "# ---------------- ADAS loop ----------------\n",
    "events = []\n",
    "last_alarm_time = collections.defaultdict(lambda: -9999)\n",
    "last_centroid = {}\n",
    "frame_id = 0\n",
    "t_start = time.time()\n",
    "print(\"Starting refined ADAS processing...\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    t_frame = time.time()\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # segmentation overlay (fast on GPU; optional)\n",
    "    seg_mask = None\n",
    "    if seg_model is not None:\n",
    "        try:\n",
    "            rseg = seg_model.predict(frame_rgb, device=DEVICE, imgsz=640, verbose=False)[0]\n",
    "            if hasattr(rseg, \"masks\") and rseg.masks is not None:\n",
    "                arr = np.array(rseg.masks.data if hasattr(rseg.masks, \"data\") else rseg.masks.numpy())\n",
    "                if arr.ndim == 3:\n",
    "                    seg_mask = np.argmax(arr, axis=0).astype(np.int32)\n",
    "                else:\n",
    "                    seg_mask = arr.astype(np.int32)\n",
    "        except Exception:\n",
    "            seg_mask = None\n",
    "\n",
    "    # lane detection (refined)\n",
    "    left_line, right_line, lane_center, debug = refined_lane_detection_v2(frame, seg_mask=seg_mask)\n",
    "\n",
    "    # optional: draw detected lane features\n",
    "    frame_proc = frame.copy()\n",
    "    if left_line is not None:\n",
    "        cv2.line(frame_proc, (left_line[0],left_line[1]), (left_line[2],left_line[3]), (0,255,0), 3)\n",
    "    if right_line is not None:\n",
    "        cv2.line(frame_proc, (right_line[0],right_line[1]), (right_line[2],right_line[3]), (0,255,0), 3)\n",
    "    if lane_center is not None:\n",
    "        (c1,c2) = lane_center\n",
    "        cv2.line(frame_proc, (c1[0],c1[1]), (c2[0],c2[1]), (255,0,0), 3)\n",
    "    if debug.get(\"hood_box\") is not None:\n",
    "        X1,Y1,X2,Y2 = debug[\"hood_box\"]\n",
    "        cv2.rectangle(frame_proc, (X1,Y1), (X2,Y2), (0,0,255), 2)\n",
    "\n",
    "    # detection + tracker input\n",
    "    detections_for_tracker = []\n",
    "    try:\n",
    "        rdet = det_model.predict(frame_rgb, device=DEVICE, imgsz=640, conf=CONF_THRESH, verbose=False)[0]\n",
    "        if hasattr(rdet, \"boxes\") and rdet.boxes is not None:\n",
    "            xyxy = rdet.boxes.xyxy.cpu().numpy() if hasattr(rdet.boxes, \"xyxy\") else np.array(rdet.boxes.xyxy)\n",
    "            confs = rdet.boxes.conf.cpu().numpy() if hasattr(rdet.boxes, \"conf\") else np.array(rdet.boxes.conf)\n",
    "            clsids = rdet.boxes.cls.cpu().numpy() if hasattr(rdet.boxes, \"cls\") else np.array(rdet.boxes.cls)\n",
    "            for (x1,y1,x2,y2), conf, clsid in zip(xyxy, confs, clsids):\n",
    "                detections_for_tracker.append(([float(x1), float(y1), float(x2), float(y2)], float(conf), str(int(clsid))))\n",
    "    except Exception as e:\n",
    "        print(\"Detection error:\", e, file=sys.stderr)\n",
    "\n",
    "    tracks = tracker.update_tracks(detections_for_tracker, frame=frame_proc)\n",
    "\n",
    "    # draw tracks and compute ADAS signals\n",
    "    for tr in tracks:\n",
    "        try:\n",
    "            if hasattr(tr, \"is_confirmed\") and (not tr.is_confirmed()):\n",
    "                continue\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            tid = int(tr.track_id)\n",
    "        except Exception:\n",
    "            tid = abs(hash(str(tr.track_id))) % 10000\n",
    "        try:\n",
    "            ltrb = tr.to_ltrb()\n",
    "        except Exception:\n",
    "            ltrb = tr.to_tlbr()\n",
    "        x1,y1,x2,y2 = map(int, ltrb)\n",
    "        cx = (x1+x2)//2; cy = y2\n",
    "        color = PALETTE[tid % len(PALETTE)]\n",
    "\n",
    "        # pixel speed fallback\n",
    "        speed_px_s = 0.0\n",
    "        speed_kmh_fallback = 0.0\n",
    "        if tid in last_centroid:\n",
    "            px,py,t_prev = last_centroid[tid]\n",
    "            dt = max(1e-6, t_frame - t_prev)\n",
    "            dist_px = math.hypot(cx - px, cy - py)\n",
    "            speed_px_s = dist_px / dt\n",
    "            speed_kmh_fallback = (speed_px_s) * 0.036\n",
    "        last_centroid[tid] = (cx,cy,t_frame)\n",
    "\n",
    "        # get metric speed and TTC if homography CSV available\n",
    "        metric_speed_kmh = None\n",
    "        metric_ttc = None\n",
    "        if use_homography:\n",
    "            fr_rows = homography_rows_by_frame.get(frame_id, [])\n",
    "            match = None\n",
    "            for r in fr_rows:\n",
    "                if int(float(r['track_id'])) == tid:\n",
    "                    match = r; break\n",
    "            if match is not None:\n",
    "                metric_speed_kmh = float(match.get('speed_kmh', 0.0))\n",
    "                metric_ttc = float(match.get('ttc_s', float('inf')))\n",
    "        else:\n",
    "            metric_ttc = (H - y2) / (speed_px_s + 1e-6) if speed_px_s>1e-6 else float('inf')\n",
    "\n",
    "        # lane departure: compute lateral px distance to lane_center\n",
    "        lane_departure = False\n",
    "        lateral_dist_px = None\n",
    "        if lane_center is not None:\n",
    "            (lx1,ly1),(lx2,ly2) = lane_center\n",
    "            pxp, pyp = cx, cy\n",
    "            num = abs((lx2-lx1)*(ly1-pyp) - (lx1-pxp)*(ly2-ly1))\n",
    "            den = math.hypot(lx2-lx1, ly2-ly1) + 1e-6\n",
    "            lateral_dist_px = num/den\n",
    "            lane_departure = lateral_dist_px > DEPARTURE_THRESHOLD_PX\n",
    "\n",
    "        # alarm decision\n",
    "        alarm = (metric_ttc is not None and metric_ttc <= TTC_THRESHOLD)\n",
    "        if alarm:\n",
    "            now = time.time()\n",
    "            last = last_alarm_time.get(tid, -9999)\n",
    "            if (now - last) >= ALARM_COOLDOWN:\n",
    "                last_alarm_time[tid] = now\n",
    "                if BEEP_ON_ALARM:\n",
    "                    try:\n",
    "                        import winsound\n",
    "                        winsound.Beep(750, 160)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "\n",
    "        # draw\n",
    "        box_color = (0,0,255) if alarm or lane_departure else color\n",
    "        cv2.rectangle(frame_proc, (x1,y1), (x2,y2), box_color, 2)\n",
    "        label_parts = [f\"ID:{tid}\"]\n",
    "        if metric_speed_kmh is not None:\n",
    "            label_parts.append(f\"{metric_speed_kmh:.1f}km/h\")\n",
    "        else:\n",
    "            label_parts.append(f\"{speed_kmh_fallback:.0f}px/s\")\n",
    "        if metric_ttc==float('inf'):\n",
    "            label_parts.append(\"TTC:inf\")\n",
    "        else:\n",
    "            label_parts.append(f\"TTC:{metric_ttc:.1f}s\")\n",
    "        if lane_departure:\n",
    "            label_parts.append(\"LANE-DEP\")\n",
    "        label = \" \".join(label_parts)\n",
    "        # draw label\n",
    "        (tw, th), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "        bx1, by1 = x1, max(0, y1 - th - 6)\n",
    "        bx2, by2 = x1 + tw + 6, by1 + th + 6\n",
    "        cv2.rectangle(frame_proc, (bx1,by1), (bx2,by2), box_color, -1)\n",
    "        cv2.putText(frame_proc, label, (x1+3, by2-4), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "        events.append({\n",
    "            \"frame\": frame_id, \"time\": t_frame - t_start, \"track_id\": tid,\n",
    "            \"x1\": x1, \"y1\": y1, \"x2\": x2, \"y2\": y2,\n",
    "            \"speed_px_s\": speed_px_s, \"metric_speed_kmh\": metric_speed_kmh,\n",
    "            \"ttc_s\": metric_ttc, \"lane_dep\": int(lane_departure)\n",
    "        })\n",
    "\n",
    "    # HUD summary\n",
    "    summary = f\"Frame:{frame_id} Objects:{len(tracks)}\"\n",
    "    cv2.putText(frame_proc, summary, (10,20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)\n",
    "\n",
    "    out.write(frame_proc)\n",
    "    frame_id += 1\n",
    "\n",
    "# cleanup\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "# save events CSV\n",
    "keys = [\"frame\",\"time\",\"track_id\",\"x1\",\"y1\",\"x2\",\"y2\",\"speed_px_s\",\"metric_speed_kmh\",\"ttc_s\",\"lane_dep\"]\n",
    "with open(EVENTS_CSV, \"w\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=keys)\n",
    "    writer.writeheader()\n",
    "    for r in events:\n",
    "        writer.writerow({k: r.get(k, None) for k in keys})\n",
    "\n",
    "print(\"DONE.\")\n",
    "print(\"Refined ADAS video saved to:\", OUTPUT_VIDEO)\n",
    "print(\"Events CSV saved to:\", EVENTS_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60526747-907c-4aa4-9d79-75ea89301325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n",
      "Segmentation model loaded.\n",
      "Using pixel-speed CSV for data: C:\\Users\\Dell\\projects\\idas_lite_seg\\run_yolov8n_seg2\\tracks_kmh_final.csv\n",
      "Starting ADAS processing with segmentation-based hood removal...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_5308\\3477211499.py:256: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  arr = np.array(rseg.masks.data if hasattr(rseg.masks, \"data\") else rseg.masks.numpy())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE.\n",
      "ADAS video saved to: C:\\Users\\Dell\\projects\\idas_lite_seg\\run_yolov8n_seg2\\output_riding_bike_adas_segmask.mp4\n",
      "Events CSV saved to: C:\\Users\\Dell\\projects\\idas_lite_seg\\run_yolov8n_seg2\\adas_events_segmask.csv\n"
     ]
    }
   ],
   "source": [
    "# Full ADAS pipeline (single cell)\n",
    "# - Uses segmentation to remove hood/driver from lane detection\n",
    "# - Robust lane detection, detection+DeepSORT tracking\n",
    "# - Metric TTC if homography CSV available, else relative TTC\n",
    "# - Outputs video and events CSV\n",
    "#\n",
    "# Kernel: Python (adas)\n",
    "# Edit paths below if needed, then run.\n",
    "\n",
    "from pathlib import Path\n",
    "import cv2, time, math, csv, numpy as np, collections, sys\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "VIDEO_PATH = Path(r\"E:/projects/riding_bike.mp4\")\n",
    "OUTPUT_VIDEO = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/output_riding_bike_adas_segmask.mp4\")\n",
    "EVENTS_CSV = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/adas_events_segmask.csv\")\n",
    "\n",
    "DETECT_WEIGHTS = \"yolov8n.pt\"\n",
    "SEG_WEIGHTS = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/weights/best.pt\")  # segmentation model (optional)\n",
    "TRACKS_CSV_HOMO = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/tracks_kmh_final_homography.csv\")\n",
    "TRACKS_CSV = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/tracks_kmh_final.csv\")\n",
    "\n",
    "DEVICE = \"cuda\"   # or \"cpu\"\n",
    "CONF_THRESH = 0.3\n",
    "\n",
    "# lane detection params\n",
    "ROI_TOP_FRAC = 0.62\n",
    "CENTER_SEARCH_W_FRAC = 0.5\n",
    "CENTER_SEARCH_H_FRAC = 0.45\n",
    "DARK_THRESH = 90\n",
    "MIN_DARK_AREA = 2000\n",
    "CANNY_LOW = 50\n",
    "CANNY_HIGH = 150\n",
    "HOUGH_THRESH = 30\n",
    "MIN_LINE_LENGTH = 40\n",
    "MAX_LINE_GAP = 20\n",
    "SLOPE_MIN = 0.35\n",
    "\n",
    "# ADAS thresholds\n",
    "TTC_THRESHOLD = 3.0         # seconds\n",
    "DEPARTURE_THRESHOLD_PX = 60 # fallback pixels threshold for lane departure\n",
    "ALARM_COOLDOWN = 2.0\n",
    "BEEP_ON_ALARM = True\n",
    "\n",
    "# segmentation mapping: which segmentation class ids mean \"drivable/road\"?\n",
    "# Based on your dataset earlier, index 0 corresponded to 'drivable'. Adjust if different.\n",
    "ROAD_CLASSES = {0}\n",
    "\n",
    "# ---------------- Sanity checks ----------------\n",
    "if not VIDEO_PATH.exists():\n",
    "    raise SystemExit(\"Input video not found: \" + str(VIDEO_PATH))\n",
    "\n",
    "# ---------------- Helpers ----------------\n",
    "def lane_mask_from_seg(seg_mask, road_classes=ROAD_CLASSES):\n",
    "    \"\"\"Return binary road mask (255 road, 0 else) from seg_mask (H,W ints).\"\"\"\n",
    "    if seg_mask is None:\n",
    "        return None\n",
    "    try:\n",
    "        mask = np.zeros_like(seg_mask, dtype=np.uint8)\n",
    "        for rc in road_classes:\n",
    "            mask[seg_mask == rc] = 255\n",
    "        return mask\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def refined_lane_detection_with_seg(frame, seg_mask=None,\n",
    "                                    roi_top_frac=ROI_TOP_FRAC,\n",
    "                                    center_search_w_frac=CENTER_SEARCH_W_FRAC,\n",
    "                                    center_search_h_frac=CENTER_SEARCH_H_FRAC,\n",
    "                                    dark_thresh=DARK_THRESH, min_dark_area=MIN_DARK_AREA,\n",
    "                                    canny_low=CANNY_LOW, canny_high=CANNY_HIGH,\n",
    "                                    hough_rho=1, hough_theta=np.pi/180, hough_thresh=HOUGH_THRESH,\n",
    "                                    min_line_length=MIN_LINE_LENGTH, max_line_gap=MAX_LINE_GAP,\n",
    "                                    slope_thresh_min=SLOPE_MIN):\n",
    "    \"\"\"Return left_line, right_line, lane_center, debug dict.\"\"\"\n",
    "    H, W = frame.shape[:2]\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "\n",
    "    top_y = int(H * roi_top_frac)\n",
    "    # ROI mask (lower portion)\n",
    "    mask_roi = np.zeros_like(gray)\n",
    "    poly = np.array([[(0,H),(0,top_y),(W,top_y),(W,H)]], dtype=np.int32)\n",
    "    cv2.fillPoly(mask_roi, poly, 255)\n",
    "\n",
    "    # search for dark hood region in bottom-center patch (fallback)\n",
    "    sw = int(W * center_search_w_frac)\n",
    "    sh = int(H * center_search_h_frac)\n",
    "    sx1 = max(0, (W - sw)//2)\n",
    "    sx2 = min(W, sx1 + sw)\n",
    "    sy1 = max(top_y, H - sh)\n",
    "    sy2 = H\n",
    "    search_patch = gray[sy1:sy2, sx1:sx2]\n",
    "    _, dark_mask = cv2.threshold(search_patch, dark_thresh, 255, cv2.THRESH_BINARY_INV)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15,15))\n",
    "    dark_mask = cv2.morphologyEx(dark_mask, cv2.MORPH_CLOSE, kernel)\n",
    "    cnts, _ = cv2.findContours(dark_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    ex_mask = np.zeros_like(gray)\n",
    "    hood_box = None\n",
    "    if cnts:\n",
    "        cnts = sorted(cnts, key=lambda c: cv2.contourArea(c), reverse=True)\n",
    "        for c in cnts:\n",
    "            area = cv2.contourArea(c)\n",
    "            if area < min_dark_area:\n",
    "                continue\n",
    "            x,y,w,h = cv2.boundingRect(c)\n",
    "            X1, Y1 = sx1 + x, sy1 + y\n",
    "            X2, Y2 = X1 + w, Y1 + h\n",
    "            pad_x = int(0.06 * W); pad_y = int(0.06 * H)\n",
    "            X1 = max(0, X1 - pad_x); Y1 = max(0, Y1 - pad_y)\n",
    "            X2 = min(W, X2 + pad_x); Y2 = min(H, Y2 + pad_y)\n",
    "            hood_box = (X1, Y1, X2, Y2)\n",
    "            cv2.rectangle(ex_mask, (X1, Y1), (X2, Y2), 255, -1)\n",
    "            break\n",
    "\n",
    "    # edges in ROI\n",
    "    edges = cv2.Canny(blur, canny_low, canny_high)\n",
    "    edges_roi = cv2.bitwise_and(edges, mask_roi)\n",
    "\n",
    "    # segmentation-based road mask if available -> keep only edges on road\n",
    "    road_mask = lane_mask_from_seg(seg_mask)\n",
    "    if road_mask is not None:\n",
    "        if road_mask.shape != edges_roi.shape:\n",
    "            road_mask = cv2.resize(road_mask, (edges_roi.shape[1], edges_roi.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "        edges_roi = cv2.bitwise_and(edges_roi, road_mask)\n",
    "\n",
    "    # exclude detected hood region (if any)\n",
    "    if hood_box is not None:\n",
    "        X1, Y1, X2, Y2 = hood_box\n",
    "        edges_roi[Y1:Y2, X1:X2] = 0\n",
    "\n",
    "    # small morphological closing\n",
    "    ker2 = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "    edges_roi = cv2.morphologyEx(edges_roi, cv2.MORPH_CLOSE, ker2)\n",
    "\n",
    "    # Hough\n",
    "    raw = cv2.HoughLinesP(edges_roi, hough_rho, hough_theta, hough_thresh,\n",
    "                          minLineLength=min_line_length, maxLineGap=max_line_gap)\n",
    "    candidates = []\n",
    "    if raw is not None:\n",
    "        for l in raw:\n",
    "            x1,y1,x2,y2 = l[0]\n",
    "            if x2 == x1:\n",
    "                slope = float('inf')\n",
    "            else:\n",
    "                slope = (y2-y1)/(x2-x1)\n",
    "            if abs(slope) < slope_thresh_min:\n",
    "                continue\n",
    "            # discard lines mostly inside hood_box area\n",
    "            if hood_box is not None:\n",
    "                hx1,hy1,hx2,hy2 = hood_box\n",
    "                midx = (x1+x2)//2; midy = (y1+y2)//2\n",
    "                if hx1 <= midx <= hx2 and hy1 <= midy <= hy2:\n",
    "                    continue\n",
    "            candidates.append((x1,y1,x2,y2,slope))\n",
    "\n",
    "    left_lines = [ (x1,y1,x2,y2) for (x1,y1,x2,y2,s) in candidates if s < 0 ]\n",
    "    right_lines = [ (x1,y1,x2,y2) for (x1,y1,x2,y2,s) in candidates if s > 0 ]\n",
    "\n",
    "    def aggregate(group):\n",
    "        if not group:\n",
    "            return None\n",
    "        xs1 = np.array([g[0] for g in group]); ys1 = np.array([g[1] for g in group])\n",
    "        xs2 = np.array([g[2] for g in group]); ys2 = np.array([g[3] for g in group])\n",
    "        return (int(np.median(xs1)), int(np.median(ys1)), int(np.median(xs2)), int(np.median(ys2)))\n",
    "\n",
    "    left = aggregate(left_lines)\n",
    "    right = aggregate(right_lines)\n",
    "\n",
    "    if left is None and right is None:\n",
    "        lane_center = None\n",
    "    elif left is None:\n",
    "        lx1,ly1,lx2,ly2 = right\n",
    "        lane_center = ((lx1 - W//4, ly1), (lx2 - W//4, ly2))\n",
    "    elif right is None:\n",
    "        rx1,ry1,rx2,ry2 = left\n",
    "        lane_center = ((rx1 + W//4, ry1), (rx2 + W//4, ry2))\n",
    "    else:\n",
    "        lx1,ly1,lx2,ly2 = left; rx1,ry1,rx2,ry2 = right\n",
    "        lane_center = ((int((lx1+rx1)/2), int((ly1+ry1)/2)), (int((lx2+rx2)/2), int((ly2+ry2)/2)))\n",
    "\n",
    "    debug = {\"edges_roi\": edges_roi, \"hood_box\": hood_box, \"candidates\": candidates, \"left_lines\": left_lines, \"right_lines\": right_lines, \"road_mask\": road_mask}\n",
    "    return left, right, lane_center, debug\n",
    "\n",
    "# ---------------- Load models ----------------\n",
    "print(\"Loading models...\")\n",
    "det_model = YOLO(DETECT_WEIGHTS)\n",
    "seg_model = None\n",
    "if SEG_WEIGHTS is not None and SEG_WEIGHTS.exists():\n",
    "    try:\n",
    "        seg_model = YOLO(str(SEG_WEIGHTS))\n",
    "        print(\"Segmentation model loaded.\")\n",
    "    except Exception as e:\n",
    "        print(\"Segmentation load failed:\", e)\n",
    "else:\n",
    "    print(\"Segmentation model not found - will use dark-region fallback only.\")\n",
    "\n",
    "# ---------------- load homography CSV if exists ----------------\n",
    "use_homography = False\n",
    "homography_rows_by_frame = {}\n",
    "if TRACKS_CSV_HOMO.exists():\n",
    "    with open(TRACKS_CSV_HOMO, newline='') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for r in reader:\n",
    "            fr = int(float(r['frame']))\n",
    "            homography_rows_by_frame.setdefault(fr, []).append(r)\n",
    "    use_homography = True\n",
    "    print(\"Using homography CSV for metric speeds/TTC:\", TRACKS_CSV_HOMO)\n",
    "elif TRACKS_CSV.exists():\n",
    "    with open(TRACKS_CSV, newline='') as f:\n",
    "        rows = [r for r in csv.DictReader(f)]\n",
    "    rows_by_frame = collections.defaultdict(list)\n",
    "    for r in rows:\n",
    "        rows_by_frame[int(float(r['frame']))].append(r)\n",
    "    print(\"Using pixel-speed CSV for data:\", TRACKS_CSV)\n",
    "else:\n",
    "    rows_by_frame = {}\n",
    "    print(\"No CSV found: metric data unavailable; will compute relative metrics.\")\n",
    "\n",
    "# ---------------- Video IO & tracker ----------------\n",
    "cap = cv2.VideoCapture(str(VIDEO_PATH))\n",
    "if not cap.isOpened():\n",
    "    raise SystemExit(\"Failed to open video.\")\n",
    "W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)); H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "FPS = cap.get(cv2.CAP_PROP_FPS) or 25.0\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"avc1\")\n",
    "out = cv2.VideoWriter(str(OUTPUT_VIDEO), fourcc, FPS, (W, H))\n",
    "tracker = DeepSort(max_age=30)\n",
    "\n",
    "palette = (np.random.RandomState(2).randint(0,255,(256,3))).astype(np.int32)\n",
    "PALETTE = [ (int(c[0]), int(c[1]), int(c[2])) for c in palette ]\n",
    "\n",
    "# ---------------- ADAS loop ----------------\n",
    "events = []\n",
    "last_alarm_time = collections.defaultdict(lambda: -9999)\n",
    "last_centroid = {}\n",
    "frame_id = 0\n",
    "t_start = time.time()\n",
    "print(\"Starting ADAS processing with segmentation-based hood removal...\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    t_frame = time.time()\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # segmentation overlay & seg_mask (we need seg_mask to get road mask)\n",
    "    seg_mask = None\n",
    "    if seg_model is not None:\n",
    "        try:\n",
    "            rseg = seg_model.predict(frame_rgb, device=DEVICE, imgsz=640, verbose=False)[0]\n",
    "            if hasattr(rseg, \"masks\") and rseg.masks is not None:\n",
    "                arr = np.array(rseg.masks.data if hasattr(rseg.masks, \"data\") else rseg.masks.numpy())\n",
    "                # if arr is (C,H,W) where channels are class maps, choose argmax; else arr is label map\n",
    "                if arr.ndim == 3:\n",
    "                    seg_mask = np.argmax(arr, axis=0).astype(np.int32)\n",
    "                else:\n",
    "                    seg_mask = arr.astype(np.int32)\n",
    "        except Exception:\n",
    "            seg_mask = None\n",
    "\n",
    "    # lane detection with seg mask to remove hood reliably\n",
    "    left_line, right_line, lane_center, debug = refined_lane_detection_with_seg(frame, seg_mask=seg_mask)\n",
    "\n",
    "    # draw lane visualization\n",
    "    frame_proc = frame.copy()\n",
    "    if left_line is not None:\n",
    "        cv2.line(frame_proc, (left_line[0],left_line[1]), (left_line[2],left_line[3]), (0,255,0), 3)\n",
    "    if right_line is not None:\n",
    "        cv2.line(frame_proc, (right_line[0],right_line[1]), (right_line[2],right_line[3]), (0,255,0), 3)\n",
    "    if lane_center is not None:\n",
    "        (c1,c2) = lane_center\n",
    "        cv2.line(frame_proc, (c1[0],c1[1]), (c2[0],c2[1]), (255,0,0), 3)\n",
    "    if debug.get(\"hood_box\") is not None:\n",
    "        X1,Y1,X2,Y2 = debug[\"hood_box\"]\n",
    "        cv2.rectangle(frame_proc, (X1,Y1), (X2,Y2), (0,0,255), 2)\n",
    "\n",
    "    # detection -> tracker\n",
    "    detections_for_tracker = []\n",
    "    try:\n",
    "        rdet = det_model.predict(frame_rgb, device=DEVICE, imgsz=640, conf=CONF_THRESH, verbose=False)[0]\n",
    "        if hasattr(rdet, \"boxes\") and rdet.boxes is not None:\n",
    "            xyxy = rdet.boxes.xyxy.cpu().numpy() if hasattr(rdet.boxes, \"xyxy\") else np.array(rdet.boxes.xyxy)\n",
    "            confs = rdet.boxes.conf.cpu().numpy() if hasattr(rdet.boxes, \"conf\") else np.array(rdet.boxes.conf)\n",
    "            clsids = rdet.boxes.cls.cpu().numpy() if hasattr(rdet.boxes, \"cls\") else np.array(rdet.boxes.cls)\n",
    "            for (x1,y1,x2,y2), conf, clsid in zip(xyxy, confs, clsids):\n",
    "                detections_for_tracker.append(([float(x1), float(y1), float(x2), float(y2)], float(conf), str(int(clsid))))\n",
    "    except Exception as e:\n",
    "        print(\"Detection error:\", e, file=sys.stderr)\n",
    "\n",
    "    tracks = tracker.update_tracks(detections_for_tracker, frame=frame_proc)\n",
    "\n",
    "    # draw tracks & ADAS logic\n",
    "    for tr in tracks:\n",
    "        try:\n",
    "            if hasattr(tr, \"is_confirmed\") and (not tr.is_confirmed()):\n",
    "                continue\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            tid = int(tr.track_id)\n",
    "        except Exception:\n",
    "            tid = abs(hash(str(tr.track_id))) % 10000\n",
    "        try:\n",
    "            ltrb = tr.to_ltrb()\n",
    "        except Exception:\n",
    "            ltrb = tr.to_tlbr()\n",
    "        x1,y1,x2,y2 = map(int, ltrb)\n",
    "        cx = (x1+x2)//2; cy = y2\n",
    "        color = PALETTE[tid % len(PALETTE)]\n",
    "\n",
    "        # pixel speed fallback\n",
    "        speed_px_s = 0.0\n",
    "        speed_kmh_fallback = 0.0\n",
    "        if tid in last_centroid:\n",
    "            px,py,t_prev = last_centroid[tid]\n",
    "            dt = max(1e-6, t_frame - t_prev)\n",
    "            dist_px = math.hypot(cx - px, cy - py)\n",
    "            speed_px_s = dist_px / dt\n",
    "            speed_kmh_fallback = (speed_px_s) * 0.036\n",
    "        last_centroid[tid] = (cx,cy,t_frame)\n",
    "\n",
    "        # metric speed & TTC from homography CSV if available\n",
    "        metric_speed_kmh = None\n",
    "        metric_ttc = None\n",
    "        if use_homography:\n",
    "            fr_rows = homography_rows_by_frame.get(frame_id, [])\n",
    "            match = None\n",
    "            for r in fr_rows:\n",
    "                if int(float(r['track_id'])) == tid:\n",
    "                    match = r; break\n",
    "            if match is not None:\n",
    "                metric_speed_kmh = float(match.get('speed_kmh', 0.0))\n",
    "                metric_ttc = float(match.get('ttc_s', float('inf')))\n",
    "        else:\n",
    "            metric_ttc = (H - y2) / (speed_px_s + 1e-6) if speed_px_s>1e-6 else float('inf')\n",
    "\n",
    "        # lane departure px distance to lane_center\n",
    "        lane_departure = False\n",
    "        lateral_dist_px = None\n",
    "        if lane_center is not None:\n",
    "            (lx1,ly1),(lx2,ly2) = lane_center\n",
    "            pxp, pyp = cx, cy\n",
    "            num = abs((lx2-lx1)*(ly1-pyp) - (lx1-pxp)*(ly2-ly1))\n",
    "            den = math.hypot(lx2-lx1, ly2-ly1) + 1e-6\n",
    "            lateral_dist_px = num/den\n",
    "            lane_departure = lateral_dist_px > DEPARTURE_THRESHOLD_PX\n",
    "\n",
    "        # alarm decision\n",
    "        alarm = (metric_ttc is not None and metric_ttc <= TTC_THRESHOLD)\n",
    "        if alarm:\n",
    "            now = time.time()\n",
    "            last = last_alarm_time.get(tid, -9999)\n",
    "            if (now - last) >= ALARM_COOLDOWN:\n",
    "                last_alarm_time[tid] = now\n",
    "                if BEEP_ON_ALARM:\n",
    "                    try:\n",
    "                        import winsound\n",
    "                        winsound.Beep(750, 160)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "\n",
    "        # draw\n",
    "        box_color = (0,0,255) if alarm or lane_departure else color\n",
    "        cv2.rectangle(frame_proc, (x1,y1), (x2,y2), box_color, 2)\n",
    "        label_parts = [f\"ID:{tid}\"]\n",
    "        if metric_speed_kmh is not None:\n",
    "            label_parts.append(f\"{metric_speed_kmh:.1f}km/h\")\n",
    "        else:\n",
    "            label_parts.append(f\"{speed_kmh_fallback:.0f}px/s\")\n",
    "        if metric_ttc==float('inf'):\n",
    "            label_parts.append(\"TTC:inf\")\n",
    "        else:\n",
    "            label_parts.append(f\"TTC:{metric_ttc:.1f}s\")\n",
    "        if lane_departure:\n",
    "            label_parts.append(\"LANE-DEP\")\n",
    "        label = \" \".join(label_parts)\n",
    "        (tw, th), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "        bx1, by1 = x1, max(0, y1 - th - 6)\n",
    "        bx2, by2 = x1 + tw + 6, by1 + th + 6\n",
    "        cv2.rectangle(frame_proc, (bx1,by1), (bx2,by2), box_color, -1)\n",
    "        cv2.putText(frame_proc, label, (x1+3, by2-4), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "        events.append({\n",
    "            \"frame\": frame_id, \"time\": t_frame - t_start, \"track_id\": tid,\n",
    "            \"x1\": x1, \"y1\": y1, \"x2\": x2, \"y2\": y2,\n",
    "            \"speed_px_s\": speed_px_s, \"metric_speed_kmh\": metric_speed_kmh,\n",
    "            \"ttc_s\": metric_ttc, \"lane_dep\": int(lane_departure)\n",
    "        })\n",
    "\n",
    "    # HUD summary\n",
    "    summary = f\"Frame:{frame_id} Objects:{len(tracks)}\"\n",
    "    cv2.putText(frame_proc, summary, (10,20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)\n",
    "\n",
    "    out.write(frame_proc)\n",
    "    frame_id += 1\n",
    "\n",
    "# cleanup\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "# save events CSV\n",
    "keys = [\"frame\",\"time\",\"track_id\",\"x1\",\"y1\",\"x2\",\"y2\",\"speed_px_s\",\"metric_speed_kmh\",\"ttc_s\",\"lane_dep\"]\n",
    "with open(EVENTS_CSV, \"w\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=keys)\n",
    "    writer.writeheader()\n",
    "    for r in events:\n",
    "        writer.writerow({k: r.get(k, None) for k in keys})\n",
    "\n",
    "print(\"DONE.\")\n",
    "print(\"ADAS video saved to:\", OUTPUT_VIDEO)\n",
    "print(\"Events CSV saved to:\", EVENTS_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7535613c-d169-4804-99b2-0eae9fe7ea2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading YOLO model...\n",
      "Segmentation model loaded.\n",
      "Traffic-light class from model present? True\n",
      "Starting ADAS + TLD processing...\n",
      "DONE.\n",
      "Output video: C:\\Users\\Dell\\projects\\idas_lite_seg\\run_yolov8n_seg2\\output_riding_bike_adas_tld.mp4\n",
      "Events CSV: C:\\Users\\Dell\\projects\\idas_lite_seg\\run_yolov8n_seg2\\adas_events_tld.csv\n"
     ]
    }
   ],
   "source": [
    "# ADAS + Traffic Light Detection (integrated)\n",
    "# Kernel: Python (adas)\n",
    "# Outputs: video with TLD overlays and events CSV including traffic_light_state\n",
    "#\n",
    "# Paste and run. Adjust PATHS if needed.\n",
    "\n",
    "from pathlib import Path\n",
    "import cv2, time, math, csv, numpy as np, collections, sys\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "VIDEO_PATH = Path(r\"E:/projects/riding_bike.mp4\")\n",
    "OUTPUT_VIDEO = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/output_riding_bike_adas_tld.mp4\")\n",
    "EVENTS_CSV = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/adas_events_tld.csv\")\n",
    "\n",
    "DETECT_WEIGHTS = \"yolov8n.pt\"   # detection model (COCO may contain traffic light class)\n",
    "SEG_WEIGHTS = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/weights/best.pt\")  # optional\n",
    "USE_MODEL_TL_CLASS_ID = 9  # COCO traffic light class id (if model trained on COCO or similar)\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "CONF_THRESH = 0.25\n",
    "\n",
    "# TLD params (upper ROI)\n",
    "TL_ROI_TOP_FRAC = 0.0    # top of ROI (as fraction of H)\n",
    "TL_ROI_BOTTOM_FRAC = 0.45  # bottom of ROI (upper 45% of frame)\n",
    "MIN_TL_AREA = 20         # tiny blobs ignored\n",
    "\n",
    "# color thresholds (HSV) for fallback detection\n",
    "# red uses two ranges (low and high hue)\n",
    "RED_RANGE1 = ((0, 80, 50), (10, 255, 255))\n",
    "RED_RANGE2 = ((160, 80, 50), (179, 255, 255))\n",
    "YELLOW_RANGE = ((15, 100, 100), (35, 255, 255))\n",
    "GREEN_RANGE = ((40, 60, 60), (90, 255, 255))\n",
    "\n",
    "# other ADAS params (kept modest)\n",
    "TTC_THRESHOLD = 3.0\n",
    "DEPARTURE_THRESHOLD_PX = 60\n",
    "ALARM_COOLDOWN = 2.0\n",
    "BEEP_ON_ALARM = True\n",
    "\n",
    "# ---------------- sanity ----------------\n",
    "if not VIDEO_PATH.exists():\n",
    "    raise SystemExit(\"Video not found: \" + str(VIDEO_PATH))\n",
    "\n",
    "# ---------------- load models ----------------\n",
    "print(\"Loading YOLO model...\")\n",
    "det_model = YOLO(DETECT_WEIGHTS)\n",
    "\n",
    "seg_model = None\n",
    "if SEG_WEIGHTS is not None and SEG_WEIGHTS.exists():\n",
    "    try:\n",
    "        seg_model = YOLO(str(SEG_WEIGHTS))\n",
    "        print(\"Segmentation model loaded.\")\n",
    "    except Exception as e:\n",
    "        print(\"Segmentation load failed:\", e)\n",
    "\n",
    "# ---------------- helper: color-based traffic light detector (fallback) ----------------\n",
    "def detect_tl_color_fallback(frame, tl_roi_top_frac=TL_ROI_TOP_FRAC, tl_roi_bottom_frac=TL_ROI_BOTTOM_FRAC):\n",
    "    \"\"\"Return best (state, bbox) or (None, None). state in {'red','yellow','green'}\"\"\"\n",
    "    H,W = frame.shape[:2]\n",
    "    y1 = int(H * tl_roi_top_frac)\n",
    "    y2 = int(H * tl_roi_bottom_frac)\n",
    "    roi = frame[y1:y2, 0:W]\n",
    "    if roi.size == 0:\n",
    "        return None, None\n",
    "    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    def mask_from_range(rng):\n",
    "        lower, upper = rng\n",
    "        lower = np.array(lower, dtype=np.uint8); upper = np.array(upper, dtype=np.uint8)\n",
    "        return cv2.inRange(hsv, lower, upper)\n",
    "\n",
    "    # red (two ranges)\n",
    "    m1 = mask_from_range(RED_RANGE1)\n",
    "    m2 = mask_from_range(RED_RANGE2)\n",
    "    red_mask = cv2.bitwise_or(m1, m2)\n",
    "    yellow_mask = mask_from_range(YELLOW_RANGE)\n",
    "    green_mask = mask_from_range(GREEN_RANGE)\n",
    "\n",
    "    # morphological cleanup\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
    "    for m in (red_mask, yellow_mask, green_mask):\n",
    "        cv2.morphologyEx(m, cv2.MORPH_OPEN, kernel, dst=m)\n",
    "\n",
    "    def find_largest(mask):\n",
    "        cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if not cnts:\n",
    "            return None\n",
    "        cnts = sorted(cnts, key=cv2.contourArea, reverse=True)\n",
    "        c = cnts[0]\n",
    "        a = cv2.contourArea(c)\n",
    "        if a < MIN_TL_AREA:\n",
    "            return None\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        # convert to full-frame coords\n",
    "        return (x, y + y1, x+w, y + y1 + h, a)\n",
    "\n",
    "    # check red, yellow, green in priority order red->yellow->green\n",
    "    red_box = find_largest(red_mask)\n",
    "    if red_box is not None:\n",
    "        return \"red\", red_box\n",
    "    yellow_box = find_largest(yellow_mask)\n",
    "    if yellow_box is not None:\n",
    "        return \"yellow\", yellow_box\n",
    "    green_box = find_largest(green_mask)\n",
    "    if green_box is not None:\n",
    "        return \"green\", green_box\n",
    "    return None, None\n",
    "\n",
    "# ---------------- video IO & tracker ----------------\n",
    "cap = cv2.VideoCapture(str(VIDEO_PATH))\n",
    "if not cap.isOpened():\n",
    "    raise SystemExit(\"Failed to open video.\")\n",
    "W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)); H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "FPS = cap.get(cv2.CAP_PROP_FPS) or 25.0\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"avc1\")  # H.264\n",
    "out = cv2.VideoWriter(str(OUTPUT_VIDEO), fourcc, FPS, (W, H))\n",
    "tracker = DeepSort(max_age=30)\n",
    "\n",
    "palette = (np.random.RandomState(2).randint(0,255,(256,3))).astype(np.int32)\n",
    "PALETTE = [ (int(c[0]), int(c[1]), int(c[2])) for c in palette ]\n",
    "\n",
    "# ---------------- main loop ----------------\n",
    "events = []\n",
    "last_alarm_time = collections.defaultdict(lambda: -9999)\n",
    "last_centroid = {}\n",
    "frame_id = 0\n",
    "t_start = time.time()\n",
    "\n",
    "# Determine whether model likely has traffic-light class by running a small probe (first frame)\n",
    "probe_has_tl_class = False\n",
    "try:\n",
    "    # load first frame to probe\n",
    "    cap_probe = cv2.VideoCapture(str(VIDEO_PATH))\n",
    "    retp, fp = cap_probe.read()\n",
    "    cap_probe.release()\n",
    "    if retp:\n",
    "        rprobe = det_model.predict(cv2.cvtColor(fp, cv2.COLOR_BGR2RGB), device=DEVICE, imgsz=640, conf=0.4, verbose=False)[0]\n",
    "        if hasattr(rprobe, \"boxes\") and rprobe.boxes is not None and hasattr(rprobe, \"names\"):\n",
    "            # check whether the names mapping includes 'traffic light' or class id 9 exists\n",
    "            names_map = rprobe.names if hasattr(rprobe, \"names\") else {}\n",
    "            # Look for name containing 'traffic' or id=9 known\n",
    "            if any((\"traffic\" in str(n).lower() or str(n).lower()==\"traffic light\" or i==USE_MODEL_TL_CLASS_ID) for i,n in names_map.items()):\n",
    "                probe_has_tl_class = True\n",
    "except Exception:\n",
    "    probe_has_tl_class = False\n",
    "\n",
    "print(\"Traffic-light class from model present?\" , probe_has_tl_class)\n",
    "\n",
    "print(\"Starting ADAS + TLD processing...\")\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    t_frame = time.time()\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Run detection (YOLO) once per frame (we'll reuse for TLD if model supports class)\n",
    "    detections_for_tracker = []\n",
    "    try:\n",
    "        rdet = det_model.predict(frame_rgb, device=DEVICE, imgsz=640, conf=CONF_THRESH, verbose=False)[0]\n",
    "        # collect boxes for tracker\n",
    "        if hasattr(rdet, \"boxes\") and rdet.boxes is not None:\n",
    "            xyxy = rdet.boxes.xyxy.cpu().numpy() if hasattr(rdet.boxes, \"xyxy\") else np.array(rdet.boxes.xyxy)\n",
    "            confs = rdet.boxes.conf.cpu().numpy() if hasattr(rdet.boxes, \"conf\") else np.array(rdet.boxes.conf)\n",
    "            clsids = rdet.boxes.cls.cpu().numpy() if hasattr(rdet.boxes, \"cls\") else np.array(rdet.boxes.cls)\n",
    "            for (x1,y1,x2,y2), conf, clsid in zip(xyxy, confs, clsids):\n",
    "                detections_for_tracker.append(([float(x1), float(y1), float(x2), float(y2)], float(conf), str(int(clsid))))\n",
    "    except Exception as e:\n",
    "        print(\"Detection error:\", e, file=sys.stderr)\n",
    "        rdet = None\n",
    "\n",
    "    # Track\n",
    "    tracks = tracker.update_tracks(detections_for_tracker, frame=frame)\n",
    "\n",
    "    # Traffic light detection: prefer model-based if available\n",
    "    tl_state = None\n",
    "    tl_box = None\n",
    "    try:\n",
    "        if probe_has_tl_class and rdet is not None:\n",
    "            # parse rdet boxes and names\n",
    "            names = rdet.names if hasattr(rdet, \"names\") else {}\n",
    "            # iterate predicted boxes and find traffic-light class (either by name or id)\n",
    "            if hasattr(rdet, \"boxes\") and rdet.boxes is not None:\n",
    "                xyxy = rdet.boxes.xyxy.cpu().numpy() if hasattr(rdet.boxes, \"xyxy\") else np.array(rdet.boxes.xyxy)\n",
    "                confs = rdet.boxes.conf.cpu().numpy() if hasattr(rdet.boxes, \"conf\") else np.array(rdet.boxes.conf)\n",
    "                clsids = rdet.boxes.cls.cpu().numpy() if hasattr(rdet.boxes, \"cls\") else np.array(rdet.boxes.cls)\n",
    "                best_conf = 0.0\n",
    "                for (x1,y1,x2,y2), conf, clsid in zip(xyxy, confs, clsids):\n",
    "                    clsid = int(clsid)\n",
    "                    name = str(names.get(clsid, \"\")).lower() if names is not None else \"\"\n",
    "                    if (\"traffic\" in name) or (clsid == USE_MODEL_TL_CLASS_ID):\n",
    "                        if conf > best_conf:\n",
    "                            best_conf = float(conf)\n",
    "                            tl_state = \"detected\"   # model may not give color; we optionally classify color below by cropping\n",
    "                            tl_box = (int(x1), int(y1), int(x2), int(y2))\n",
    "                # if we found a TL box, try color classification inside it\n",
    "                if tl_box is not None:\n",
    "                    x1,y1,x2,y2 = tl_box\n",
    "                    crop = frame[y1:y2, x1:x2]\n",
    "                    # classify dominant color using HSV mean\n",
    "                    if crop.size > 0:\n",
    "                        hsv = cv2.cvtColor(crop, cv2.COLOR_BGR2HSV)\n",
    "                        h_mean = hsv[...,0].mean()\n",
    "                        s_mean = hsv[...,1].mean()\n",
    "                        v_mean = hsv[...,2].mean()\n",
    "                        # heuristic thresholds\n",
    "                        if ( (h_mean < 15 or h_mean>160) and s_mean>80 and v_mean>50):\n",
    "                            tl_state = \"red\"\n",
    "                        elif (15 <= h_mean <= 40 and s_mean>90):\n",
    "                            tl_state = \"yellow\"\n",
    "                        elif (40 < h_mean <= 100 and s_mean>60):\n",
    "                            tl_state = \"green\"\n",
    "                        else:\n",
    "                            tl_state = \"unknown\"\n",
    "        # model-based not available or no TL box found -> fallback to color-based ROI search\n",
    "        if tl_state is None:\n",
    "            st, box = detect_tl_color_fallback(frame)\n",
    "            if st is not None:\n",
    "                tl_state, tl_box = st, box[:4]\n",
    "    except Exception as e:\n",
    "        # any error in TL detection -> fallback color detect\n",
    "        tl_state = None; tl_box = None\n",
    "        try:\n",
    "            st, box = detect_tl_color_fallback(frame)\n",
    "            if st is not None:\n",
    "                tl_state, tl_box = st, box[:4]\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # draw TL overlay if found\n",
    "    frame_proc = frame.copy()\n",
    "    if tl_box is not None:\n",
    "        x1,y1,x2,y2 = map(int, tl_box)\n",
    "        color = (0,0,255) if tl_state==\"red\" else (0,255,255) if tl_state==\"yellow\" else (0,255,0) if tl_state==\"green\" else (200,200,200)\n",
    "        cv2.rectangle(frame_proc, (x1,y1), (x2,y2), color, 2)\n",
    "        txt = f\"TL:{tl_state}\"\n",
    "        cv2.putText(frame_proc, txt, (x1, max(0,y1-10)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "    # draw tracked objects and keep ADAS logging (similar to before but simplified)\n",
    "    for tr in tracks:\n",
    "        try:\n",
    "            if hasattr(tr, \"is_confirmed\") and (not tr.is_confirmed()):\n",
    "                continue\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            tid = int(tr.track_id)\n",
    "        except Exception:\n",
    "            tid = abs(hash(str(tr.track_id))) % 10000\n",
    "        try:\n",
    "            ltrb = tr.to_ltrb()\n",
    "        except Exception:\n",
    "            ltrb = tr.to_tlbr()\n",
    "        x1,y1,x2,y2 = map(int, ltrb)\n",
    "        cx = (x1+x2)//2; cy = y2\n",
    "        color = PALETTE[tid % len(PALETTE)]\n",
    "\n",
    "        # compute pixel speed fallback\n",
    "        speed_px_s = 0.0\n",
    "        if tid in last_centroid:\n",
    "            px,py,t_prev = last_centroid[tid]\n",
    "            dt = max(1e-6, t_frame - t_prev)\n",
    "            dist_px = math.hypot(cx - px, cy - py)\n",
    "            speed_px_s = dist_px / dt\n",
    "        last_centroid[tid] = (cx,cy,t_frame)\n",
    "\n",
    "        # draw box & label\n",
    "        cv2.rectangle(frame_proc, (x1,y1), (x2,y2), color, 2)\n",
    "        cv2.putText(frame_proc, f\"ID:{tid}\", (x1, max(0,y1-10)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "\n",
    "        events.append({\n",
    "            \"frame\": frame_id, \"time\": t_frame - t_start, \"track_id\": tid,\n",
    "            \"x1\": x1, \"y1\": y1, \"x2\": x2, \"y2\": y2,\n",
    "            \"speed_px_s\": speed_px_s, \"traffic_light_state\": tl_state\n",
    "        })\n",
    "\n",
    "    # HUD: show current TL state at top-left\n",
    "    hud_text = f\"TL: {tl_state if tl_state is not None else 'none'}  Frame:{frame_id}\"\n",
    "    cv2.putText(frame_proc, hud_text, (10,25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "    out.write(frame_proc)\n",
    "    frame_id += 1\n",
    "\n",
    "# cleanup\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "# save events csv (traffic_light_state included)\n",
    "keys = [\"frame\",\"time\",\"track_id\",\"x1\",\"y1\",\"x2\",\"y2\",\"speed_px_s\",\"traffic_light_state\"]\n",
    "with open(EVENTS_CSV, \"w\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=keys)\n",
    "    writer.writeheader()\n",
    "    for r in events:\n",
    "        writer.writerow({k: r.get(k, None) for k in keys})\n",
    "\n",
    "print(\"DONE.\")\n",
    "print(\"Output video:\", OUTPUT_VIDEO)\n",
    "print(\"Events CSV:\", EVENTS_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "344b28bc-2e47-450c-bb90-1bffeecf8635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected: red  bbox: (362, 191, 392, 216)  score: 378.0\n",
      "Debug image saved to: tl_color_debug.png\n"
     ]
    }
   ],
   "source": [
    "# Traffic light color detector (robust HSV + blob filtering)\n",
    "# Kernel: Python (adas)\n",
    "from pathlib import Path\n",
    "import cv2, numpy as np, math\n",
    "\n",
    "VIDEO_PATH = Path(r\"E:/projects/riding_bike.mp4\")\n",
    "DEBUG_OUT = Path(\"tl_color_debug.png\")\n",
    "\n",
    "# ---------- PARAMETERS (tune if necessary) ----------\n",
    "TL_ROI_TOP_FRAC = 0.0        # start of ROI (0 = top of frame)\n",
    "TL_ROI_BOTTOM_FRAC = 0.45    # bottom of ROI (upper 45% of frame)\n",
    "MIN_TL_AREA = 40             # min area (in pixels) to consider a light blob\n",
    "MAX_TL_AREA = 20000          # max area to ignore huge regions\n",
    "ASPECT_RATIO_MAX = 2.5       # discard overly wide blobs\n",
    "CIRCULARITY_MIN = 0.3        # solidity/shape measure (lower->allow more shapes)\n",
    "\n",
    "# HSV ranges (you can tune to your environment)\n",
    "RED_RANGE1 = ((0, 90, 60), (10, 255, 255))\n",
    "RED_RANGE2 = ((160, 90, 60), (179, 255, 255))\n",
    "YELLOW_RANGE = ((15, 100, 100), (40, 255, 255))\n",
    "GREEN_RANGE = ((40, 60, 60), (100, 255, 255))\n",
    "\n",
    "# morphological kernel\n",
    "KERNEL = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
    "\n",
    "# ---------- detector function ----------\n",
    "def detect_traffic_light_color(frame,\n",
    "                               tl_roi_top_frac=TL_ROI_TOP_FRAC,\n",
    "                               tl_roi_bottom_frac=TL_ROI_BOTTOM_FRAC,\n",
    "                               min_area=MIN_TL_AREA):\n",
    "    \"\"\"\n",
    "    Return (state, bbox, score, debug_masks)\n",
    "      - state: 'red' | 'yellow' | 'green' | None\n",
    "      - bbox: (x1,y1,x2,y2) of detected light in full-frame coords or None\n",
    "      - score: heuristic score (area or combined) for ranking\n",
    "      - debug_masks: dict of masks for visualization\n",
    "    \"\"\"\n",
    "    H, W = frame.shape[:2]\n",
    "    y1 = int(H * tl_roi_top_frac)\n",
    "    y2 = int(H * tl_roi_bottom_frac)\n",
    "    roi = frame[y1:y2, 0:W].copy()\n",
    "    if roi.size == 0:\n",
    "        return None, None, 0.0, {}\n",
    "\n",
    "    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    def mask_from_range(rng):\n",
    "        low, high = rng\n",
    "        low = np.array(low, dtype=np.uint8); high = np.array(high, dtype=np.uint8)\n",
    "        m = cv2.inRange(hsv, low, high)\n",
    "        m = cv2.morphologyEx(m, cv2.MORPH_OPEN, KERNEL)\n",
    "        m = cv2.morphologyEx(m, cv2.MORPH_CLOSE, KERNEL)\n",
    "        return m\n",
    "\n",
    "    masks = {}\n",
    "    masks['red1'] = mask_from_range(RED_RANGE1)\n",
    "    masks['red2'] = mask_from_range(RED_RANGE2)\n",
    "    masks['red'] = cv2.bitwise_or(masks['red1'], masks['red2'])\n",
    "    masks['yellow'] = mask_from_range(YELLOW_RANGE)\n",
    "    masks['green'] = mask_from_range(GREEN_RANGE)\n",
    "\n",
    "    # helper to find candidate blobs in a mask\n",
    "    def find_best_blob(mask):\n",
    "        cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        best = None  # (area, bbox, circularity)\n",
    "        for c in cnts:\n",
    "            area = cv2.contourArea(c)\n",
    "            if area < min_area or area > MAX_TL_AREA:\n",
    "                continue\n",
    "            x,y,w,h = cv2.boundingRect(c)\n",
    "            aspect = float(w)/float(h+1e-6)\n",
    "            if aspect > ASPECT_RATIO_MAX:  # too wide, not a light\n",
    "                continue\n",
    "            # circularity / solidity measure\n",
    "            hull = cv2.convexHull(c)\n",
    "            hull_area = cv2.contourArea(hull) if len(hull) > 2 else area\n",
    "            circularity = float(area) / (hull_area + 1e-6)\n",
    "            # score prefers larger area and decent circularity\n",
    "            score = area * (0.5 + 0.5 * min(1.0, circularity / (CIRCULARITY_MIN+1e-6)))\n",
    "            if best is None or score > best[0]:\n",
    "                best = (score, (x,y,w,h), circularity, area)\n",
    "        return best\n",
    "\n",
    "    cand_red = find_best_blob(masks['red'])\n",
    "    cand_yellow = find_best_blob(masks['yellow'])\n",
    "    cand_green = find_best_blob(masks['green'])\n",
    "\n",
    "    # Priority: red > yellow > green (you can change)\n",
    "    cands = []\n",
    "    if cand_red is not None:\n",
    "        cands.append(('red',) + cand_red)\n",
    "    if cand_yellow is not None:\n",
    "        cands.append(('yellow',) + cand_yellow)\n",
    "    if cand_green is not None:\n",
    "        cands.append(('green',) + cand_green)\n",
    "\n",
    "    # If no candidates, return None\n",
    "    if not cands:\n",
    "        return None, None, 0.0, masks\n",
    "\n",
    "    # choose best by score (but if close, prefer red then yellow)\n",
    "    # sort by score desc\n",
    "    cands.sort(key=lambda x: x[1], reverse=True)\n",
    "    # enforced priority: if red exists with reasonable score choose it\n",
    "    names = [c[0] for c in cands]\n",
    "    # priority selection\n",
    "    for preferred in ['red','yellow','green']:\n",
    "        for cand in cands:\n",
    "            if cand[0] == preferred:\n",
    "                _, score, bbox, circ, area = cand\n",
    "                x,y,w,h = bbox\n",
    "                # convert bbox coords to full frame\n",
    "                fx1, fy1, fx2, fy2 = x, y + y1, x + w, y + h + y1\n",
    "                return preferred, (fx1, fy1, fx2, fy2), float(score), masks\n",
    "\n",
    "    # fallback pick best\n",
    "    pref = cands[0]\n",
    "    _, score, bbox, circ, area = pref\n",
    "    x,y,w,h = bbox\n",
    "    fx1, fy1, fx2, fy2 = x, y + y1, x + w, y + h + y1\n",
    "    return pref[0], (fx1, fy1, fx2, fy2), float(score), masks\n",
    "\n",
    "# ---------- quick test on first frame ----------\n",
    "cap = cv2.VideoCapture(str(VIDEO_PATH))\n",
    "ret, frame0 = cap.read()\n",
    "cap.release()\n",
    "if not ret:\n",
    "    raise SystemExit(\"Cannot read video frame.\")\n",
    "\n",
    "state, bbox, score, debug_masks = detect_traffic_light_color(frame0)\n",
    "print(\"Detected:\", state, \" bbox:\", bbox, \" score:\", score)\n",
    "\n",
    "# draw debug image\n",
    "vis = frame0.copy()\n",
    "H, W = frame0.shape[:2]\n",
    "# draw ROI rect\n",
    "y1 = int(H * TL_ROI_TOP_FRAC); y2 = int(H * TL_ROI_BOTTOM_FRAC)\n",
    "cv2.rectangle(vis, (0,y1), (W,y2), (255,255,0), 2)\n",
    "\n",
    "# overlay masks (small thumbnails on right)\n",
    "thumb_h = 120\n",
    "thumbs = []\n",
    "for k in ['red','yellow','green']:\n",
    "    m = debug_masks.get(k)\n",
    "    if m is None:\n",
    "        m = np.zeros((y2-y1, W), dtype=np.uint8)\n",
    "    m_color = cv2.cvtColor(m, cv2.COLOR_GRAY2BGR)\n",
    "    m_small = cv2.resize(m_color, (int(W*0.25), thumb_h))\n",
    "    thumbs.append(m_small)\n",
    "# stack thumbs vertically\n",
    "stacked = np.vstack(thumbs)\n",
    "# paste on right side\n",
    "h_s, w_s = stacked.shape[:2]\n",
    "vis[10:10+h_s, -w_s-10:-10] = stacked\n",
    "\n",
    "# draw bbox and state\n",
    "if bbox is not None:\n",
    "    x1,y1b,x2,y2b = bbox\n",
    "    color = (0,0,255) if state=='red' else (0,255,255) if state=='yellow' else (0,255,0)\n",
    "    cv2.rectangle(vis, (x1,y1b), (x2,y2b), color, 2)\n",
    "    cv2.putText(vis, f\"TL:{state} s={score:.1f}\", (x1, max(0,y1b-10)), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "\n",
    "# save debug image\n",
    "cv2.imwrite(str(DEBUG_OUT), vis)\n",
    "print(\"Debug image saved to:\", DEBUG_OUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ab87066-631e-4b88-ae89-7facbc81862e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing TL color detection over full video...\n",
      "Done. Processed frames: 870 Elapsed: 11.5126314163208\n",
      "Output video: C:\\Users\\Dell\\projects\\idas_lite_seg\\run_yolov8n_seg2\\output_tl_color_full.mp4\n",
      "Events CSV: C:\\Users\\Dell\\projects\\idas_lite_seg\\run_yolov8n_seg2\\tl_events.csv\n"
     ]
    }
   ],
   "source": [
    "# Run Traffic-Light color detector over full video -> annotated video + CSV\n",
    "# Kernel: Python (adas)\n",
    "\n",
    "from pathlib import Path\n",
    "import cv2, time, csv, numpy as np, math, collections\n",
    "from datetime import datetime\n",
    "\n",
    "# ---------- Paths & params ----------\n",
    "VIDEO_PATH = Path(r\"E:/projects/riding_bike.mp4\")\n",
    "OUT_VIDEO = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/output_tl_color_full.mp4\")\n",
    "OUT_CSV   = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/tl_events.csv\")\n",
    "\n",
    "# re-use detector from debug cell (copy/paste detector code here)\n",
    "TL_ROI_TOP_FRAC = 0.0\n",
    "TL_ROI_BOTTOM_FRAC = 0.45\n",
    "MIN_TL_AREA = 40\n",
    "MAX_TL_AREA = 20000\n",
    "ASPECT_RATIO_MAX = 2.5\n",
    "CIRCULARITY_MIN = 0.3\n",
    "KERNEL = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
    "\n",
    "RED_RANGE1 = ((0, 90, 60), (10, 255, 255))\n",
    "RED_RANGE2 = ((160, 90, 60), (179, 255, 255))\n",
    "YELLOW_RANGE = ((15, 100, 100), (40, 255, 255))\n",
    "GREEN_RANGE = ((40, 60, 60), (100, 255, 255))\n",
    "\n",
    "BEEP_ON_RED = True\n",
    "ALARM_COOLDOWN = 2.0  # seconds between beeps\n",
    "\n",
    "UPSAMPLE_FOR_CLASS = True  # set False to skip crop upsample refinement\n",
    "UPSAMPLE_SCALE = 2         # upsample factor for small boxes before re-classify\n",
    "MIN_AREA_FOR_UPSAMPLE = 60\n",
    "\n",
    "# ---------- helper functions (same as debug) ----------\n",
    "def mask_from_range_hsv(hsv, rng):\n",
    "    low, high = rng\n",
    "    low = np.array(low, dtype=np.uint8); high = np.array(high, dtype=np.uint8)\n",
    "    m = cv2.inRange(hsv, low, high)\n",
    "    m = cv2.morphologyEx(m, cv2.MORPH_OPEN, KERNEL)\n",
    "    m = cv2.morphologyEx(m, cv2.MORPH_CLOSE, KERNEL)\n",
    "    return m\n",
    "\n",
    "def find_best_blob(mask, min_area=MIN_TL_AREA):\n",
    "    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    best = None\n",
    "    for c in cnts:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area < min_area or area > MAX_TL_AREA:\n",
    "            continue\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        aspect = float(w)/float(h+1e-6)\n",
    "        if aspect > ASPECT_RATIO_MAX:\n",
    "            continue\n",
    "        hull = cv2.convexHull(c)\n",
    "        hull_area = cv2.contourArea(hull) if len(hull) > 2 else area\n",
    "        circularity = float(area) / (hull_area + 1e-6)\n",
    "        score = area * (0.5 + 0.5 * min(1.0, circularity / (CIRCULARITY_MIN+1e-6)))\n",
    "        if best is None or score > best[0]:\n",
    "            best = (score, (x,y,w,h), circularity, area)\n",
    "    return best\n",
    "\n",
    "def classify_crop_by_hsv(crop):\n",
    "    \"\"\"Return 'red'|'yellow'|'green'|None and score\"\"\"\n",
    "    if crop is None or crop.size==0:\n",
    "        return None, 0.0\n",
    "    hsv = cv2.cvtColor(crop, cv2.COLOR_BGR2HSV)\n",
    "    red1 = mask_from_range_hsv(hsv, RED_RANGE1)\n",
    "    red2 = mask_from_range_hsv(hsv, RED_RANGE2)\n",
    "    red = cv2.bitwise_or(red1, red2)\n",
    "    yellow = mask_from_range_hsv(hsv, YELLOW_RANGE)\n",
    "    green = mask_from_range_hsv(hsv, GREEN_RANGE)\n",
    "    br = find_best_blob(red)\n",
    "    by = find_best_blob(yellow)\n",
    "    bg = find_best_blob(green)\n",
    "    cands = []\n",
    "    if br is not None:\n",
    "        cands.append(('red',) + br)\n",
    "    if by is not None:\n",
    "        cands.append(('yellow',) + by)\n",
    "    if bg is not None:\n",
    "        cands.append(('green',) + bg)\n",
    "    if not cands:\n",
    "        return None, 0.0\n",
    "    # prefer red>yellow>green if close; otherwise best score\n",
    "    cands.sort(key=lambda x: x[1], reverse=True)\n",
    "    for pref in ('red','yellow','green'):\n",
    "        for cand in cands:\n",
    "            if cand[0] == pref:\n",
    "                return cand[0], float(cand[1])\n",
    "    # fallback\n",
    "    return cands[0][0], float(cands[0][1])\n",
    "\n",
    "def detect_traffic_light_color_frame(frame):\n",
    "    H, W = frame.shape[:2]\n",
    "    y1 = int(H * TL_ROI_TOP_FRAC); y2 = int(H * TL_ROI_BOTTOM_FRAC)\n",
    "    roi = frame[y1:y2, 0:W].copy()\n",
    "    if roi.size == 0:\n",
    "        return None, None, 0.0, {}\n",
    "    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    masks = {}\n",
    "    masks['red1'] = mask_from_range_hsv(hsv, RED_RANGE1)\n",
    "    masks['red2'] = mask_from_range_hsv(hsv, RED_RANGE2)\n",
    "    masks['red'] = cv2.bitwise_or(masks['red1'], masks['red2'])\n",
    "    masks['yellow'] = mask_from_range_hsv(hsv, YELLOW_RANGE)\n",
    "    masks['green'] = mask_from_range_hsv(hsv, GREEN_RANGE)\n",
    "\n",
    "    cand_red = find_best_blob(masks['red'])\n",
    "    cand_yellow = find_best_blob(masks['yellow'])\n",
    "    cand_green = find_best_blob(masks['green'])\n",
    "\n",
    "    cands = []\n",
    "    if cand_red is not None:\n",
    "        cands.append(('red',) + cand_red)\n",
    "    if cand_yellow is not None:\n",
    "        cands.append(('yellow',) + cand_yellow)\n",
    "    if cand_green is not None:\n",
    "        cands.append(('green',) + cand_green)\n",
    "\n",
    "    if not cands:\n",
    "        return None, None, 0.0, masks\n",
    "\n",
    "    cands.sort(key=lambda x: x[1], reverse=True)\n",
    "    # priority red>yellow>green\n",
    "    for pref in ('red','yellow','green'):\n",
    "        for cand in cands:\n",
    "            if cand[0] == pref:\n",
    "                _, score, bbox, circ, area = cand\n",
    "                x,y,w,h = bbox\n",
    "                fx1, fy1, fx2, fy2 = x, y + y1, x + w, y + h + y1\n",
    "                return pref, (fx1, fy1, fx2, fy2), float(score), masks\n",
    "\n",
    "    # fallback\n",
    "    pref = cands[0]\n",
    "    _, score, bbox, circ, area = pref\n",
    "    x,y,w,h = bbox\n",
    "    fx1, fy1, fx2, fy2 = x, y + y1, x + w, y + h + y1\n",
    "    return pref, (fx1, fy1, fx2, fy2), float(score), masks\n",
    "\n",
    "# ---------- setup video IO ----------\n",
    "cap = cv2.VideoCapture(str(VIDEO_PATH))\n",
    "if not cap.isOpened():\n",
    "    raise SystemExit(\"Failed to open video.\")\n",
    "W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)); H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "FPS = cap.get(cv2.CAP_PROP_FPS) or 25.0\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"avc1\")\n",
    "out = cv2.VideoWriter(str(OUT_VIDEO), fourcc, FPS, (W, H))\n",
    "\n",
    "frame_id = 0\n",
    "events = []\n",
    "last_beep = -9999\n",
    "\n",
    "print(\"Processing TL color detection over full video...\")\n",
    "t0 = time.time()\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    t_frame = time.time()\n",
    "    state, bbox, score, masks = detect_traffic_light_color_frame(frame)\n",
    "\n",
    "    # optional upsample reclassification (helps tiny lights)\n",
    "    if UPSAMPLE_FOR_CLASS and bbox is not None:\n",
    "        x1,y1,x2,y2 = map(int, bbox)\n",
    "        w = x2 - x1; h = y2 - y1\n",
    "        if w*h < MIN_AREA_FOR_UPSAMPLE:\n",
    "            # upsample ROI a bit and reclassify\n",
    "            pad = 4\n",
    "            xa = max(0, x1-pad); ya = max(0, y1-pad); xb = min(W, x2+pad); yb = min(H, y2+pad)\n",
    "            crop = frame[ya:yb, xa:xb].copy()\n",
    "            if crop.size > 0:\n",
    "                crop_up = cv2.resize(crop, (int(crop.shape[1]*UPSAMPLE_SCALE), int(crop.shape[0]*UPSAMPLE_SCALE)), interpolation=cv2.INTER_CUBIC)\n",
    "                st2, sc2 = classify_crop_by_hsv(crop_up)\n",
    "                if st2 is not None:\n",
    "                    # if reclass says same or higher score prefer it\n",
    "                    state = st2\n",
    "\n",
    "    # draw on frame\n",
    "    vis = frame.copy()\n",
    "    if bbox is not None:\n",
    "        x1,y1,x2,y2 = map(int, bbox)\n",
    "        col = (0,0,255) if state=='red' else (0,255,255) if state=='yellow' else (0,255,0) if state=='green' else (200,200,200)\n",
    "        cv2.rectangle(vis, (x1,y1), (x2,y2), col, 2)\n",
    "        cv2.putText(vis, f\"TL:{state}\", (x1, max(0,y1-10)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, col, 2)\n",
    "    # HUD\n",
    "    hud = f\"TL:{state if state else 'none'}  Frame:{frame_id}\"\n",
    "    cv2.putText(vis, hud, (10,25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    out.write(vis)\n",
    "\n",
    "    # beep on red with cooldown\n",
    "    if state == 'red' and BEEP_ON_RED:\n",
    "        now = time.time()\n",
    "        if (now - last_beep) >= ALARM_COOLDOWN:\n",
    "            last_beep = now\n",
    "            try:\n",
    "                import winsound\n",
    "                winsound.Beep(700, 200)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    events.append({\n",
    "        \"frame\": frame_id,\n",
    "        \"time_s\": frame_id / FPS,\n",
    "        \"state\": state,\n",
    "        \"bbox\": bbox,\n",
    "        \"score\": score\n",
    "    })\n",
    "\n",
    "    frame_id += 1\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "# ---------- save CSV ----------\n",
    "with open(OUT_CSV, \"w\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"frame\",\"time_s\",\"state\",\"bbox\",\"score\"])\n",
    "    writer.writeheader()\n",
    "    for r in events:\n",
    "        writer.writerow({\"frame\": r[\"frame\"], \"time_s\": r[\"time_s\"], \"state\": r[\"state\"], \"bbox\": str(r[\"bbox\"]) if r[\"bbox\"] else \"\", \"score\": r[\"score\"]})\n",
    "\n",
    "print(\"Done. Processed frames:\", frame_id, \"Elapsed:\", time.time()-t0)\n",
    "print(\"Output video:\", OUT_VIDEO)\n",
    "print(\"Events CSV:\", OUT_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c27a4975-3d26-4215-9881-f48222df4705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TL detection + confirmation pass...\n",
      "Done. Frames processed: 870 Output video: C:\\Users\\Dell\\projects\\idas_lite_seg\\run_yolov8n_seg2\\output_tld_confirmed.mp4 Events CSV: C:\\Users\\Dell\\projects\\idas_lite_seg\\run_yolov8n_seg2\\tld_confirmed_events.csv\n"
     ]
    }
   ],
   "source": [
    "# Robust Traffic Light Detection with temporal confirmation\n",
    "# Kernel: Python (adas)\n",
    "# Outputs:\n",
    "#   - annotated video: output_tld_confirmed.mp4\n",
    "#   - events CSV: tld_confirmed_events.csv\n",
    "\n",
    "from pathlib import Path\n",
    "import cv2, numpy as np, math, time, csv, sys, collections\n",
    "\n",
    "# ---------------- CONFIG (edit paths if needed) ----------------\n",
    "VIDEO_PATH = Path(r\"E:/projects/riding_bike.mp4\")\n",
    "OUT_VIDEO  = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/output_tld_confirmed.mp4\")\n",
    "OUT_CSV    = Path(r\"C:/Users/Dell/projects/idas_lite_seg/run_yolov8n_seg2/tld_confirmed_events.csv\")\n",
    "\n",
    "# TL detection params\n",
    "UPPER_ROI_BOTTOM_FRAC = 0.45   # analyze only top 45% of frame\n",
    "MIN_AREA = 40                  # min blob area\n",
    "MAX_AREA = 1000                # max blob area (traffic lights are small)\n",
    "ASPECT_MIN, ASPECT_MAX = 0.4, 2.0\n",
    "CIRCULARITY_MIN = 0.25\n",
    "IOU_MATCH_THRESH = 0.35        # IoU threshold to match detections across frames\n",
    "N_CONS_CONFIRM = 3             # require this many consecutive frames to confirm a TL\n",
    "COOLDOWN_SECS = 2.0            # beep cooldown\n",
    "BEEP_ON_RED = True\n",
    "\n",
    "# HSV ranges (tune if needed)\n",
    "RED_RANGE1 = ((0, 120, 80), (10, 255, 255))\n",
    "RED_RANGE2 = ((160, 120, 80), (179, 255, 255))\n",
    "YELLOW_RANGE = ((15, 120, 120), (40, 255, 255))\n",
    "GREEN_RANGE = ((40, 80, 80), (90, 255, 255))\n",
    "\n",
    "# morphological kernel\n",
    "KERNEL = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
    "\n",
    "# ------------- utility helpers -------------\n",
    "def iou(boxA, boxB):\n",
    "    # boxes (x1,y1,x2,y2)\n",
    "    xA = max(boxA[0], boxB[0]); yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2]); yB = min(boxA[3], boxB[3])\n",
    "    interW = max(0, xB - xA); interH = max(0, yB - yA)\n",
    "    interArea = interW * interH\n",
    "    areaA = max(0, boxA[2]-boxA[0]) * max(0, boxA[3]-boxA[1])\n",
    "    areaB = max(0, boxB[2]-boxB[0]) * max(0, boxB[3]-boxB[1])\n",
    "    union = areaA + areaB - interArea + 1e-6\n",
    "    return interArea/union\n",
    "\n",
    "def mask_from_range_hsv(hsv, rng):\n",
    "    low, high = rng\n",
    "    low = np.array(low, dtype=np.uint8); high = np.array(high, dtype=np.uint8)\n",
    "    m = cv2.inRange(hsv, low, high)\n",
    "    m = cv2.morphologyEx(m, cv2.MORPH_OPEN, KERNEL)\n",
    "    m = cv2.morphologyEx(m, cv2.MORPH_CLOSE, KERNEL)\n",
    "    return m\n",
    "\n",
    "def find_color_blobs(hsv, color_ranges):\n",
    "    # returns list of candidate boxes (x,y,w,h,area,mask)\n",
    "    mask = None\n",
    "    if isinstance(color_ranges, tuple) and len(color_ranges)==2 and all(isinstance(x, tuple) for x in color_ranges):\n",
    "        # single range\n",
    "        mask = mask_from_range_hsv(hsv, color_ranges)\n",
    "    elif isinstance(color_ranges, (list,tuple)) and len(color_ranges)>1:\n",
    "        mask = None\n",
    "        for rng in color_ranges:\n",
    "            m = mask_from_range_hsv(hsv, rng)\n",
    "            mask = m if mask is None else cv2.bitwise_or(mask, m)\n",
    "    else:\n",
    "        mask = np.zeros(hsv.shape[:2], dtype=np.uint8)\n",
    "    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cands = []\n",
    "    for c in cnts:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area < MIN_AREA or area > MAX_AREA:\n",
    "            continue\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        aspect = w/(h+1e-6)\n",
    "        if aspect < ASPECT_MIN or aspect > ASPECT_MAX:\n",
    "            continue\n",
    "        perim = cv2.arcLength(c, True)\n",
    "        if perim <= 0: continue\n",
    "        circularity = 4*math.pi*(area/(perim*perim))\n",
    "        if circularity < CIRCULARITY_MIN:\n",
    "            continue\n",
    "        cands.append((x,y,w,h,area,mask))\n",
    "    return cands\n",
    "\n",
    "def detect_tl_shapes(frame):\n",
    "    \"\"\"Return list of (state, bbox) in full-frame coords. bbox = (x1,y1,x2,y2).\"\"\"\n",
    "    H,W = frame.shape[:2]\n",
    "    y1 = 0; y2 = int(H * UPPER_ROI_BOTTOM_FRAC)\n",
    "    roi = frame[y1:y2, :]\n",
    "    if roi.size == 0:\n",
    "        return []\n",
    "\n",
    "    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    # find colored blobs\n",
    "    red_cands = find_color_blobs(hsv, [RED_RANGE1, RED_RANGE2])\n",
    "    yellow_cands = find_color_blobs(hsv, YELLOW_RANGE)\n",
    "    green_cands = find_color_blobs(hsv, GREEN_RANGE)\n",
    "\n",
    "    # convert to (state, bbox)\n",
    "    res = []\n",
    "    for (x,y,w,h,area,mask) in red_cands:\n",
    "        res.append((\"red\", (x, y + y1, x+w, y + y1 + h)))\n",
    "    for (x,y,w,h,area,mask) in yellow_cands:\n",
    "        res.append((\"yellow\", (x, y + y1, x+w, y + y1 + h)))\n",
    "    for (x,y,w,h,area,mask) in green_cands:\n",
    "        res.append((\"green\", (x, y + y1, x+w, y + y1 + h)))\n",
    "\n",
    "    # now cluster by X proximity (vertical alignment). Real TL often has vertical stack -> same x center\n",
    "    clustered = []\n",
    "    used = [False]*len(res)\n",
    "    for i, (state_i, box_i) in enumerate(res):\n",
    "        if used[i]: continue\n",
    "        xi_center = (box_i[0] + box_i[2])/2\n",
    "        cluster = [(state_i, box_i)]\n",
    "        used[i] = True\n",
    "        for j, (state_j, box_j) in enumerate(res):\n",
    "            if used[j]: continue\n",
    "            xj_center = (box_j[0] + box_j[2])/2\n",
    "            if abs(xi_center - xj_center) < max(20, (box_i[2]-box_i[0])*0.6):  # similar x\n",
    "                cluster.append((state_j, box_j))\n",
    "                used[j] = True\n",
    "        # cluster -> choose highest priority state among cluster members:\n",
    "        # priority red>yellow>green\n",
    "        priority = {\"red\":3,\"yellow\":2,\"green\":1}\n",
    "        cluster.sort(key=lambda x: priority.get(x[0],0), reverse=True)\n",
    "        clustered.append(cluster[0])  # representative\n",
    "    return clustered\n",
    "\n",
    "# ------------- Temporal confirmation tracker for TLs -------------\n",
    "class TLConfirmTracker:\n",
    "    def __init__(self, iou_thresh=IOU_MATCH_THRESH, required_cons=N_CONS_CONFIRM):\n",
    "        self.iou_thresh = iou_thresh\n",
    "        self.required_cons = required_cons\n",
    "        self.entries = []  # list of dicts: {box, state, count, last_seen_time}\n",
    "        self.confirmed = []  # confirmed entries (same dict but flagged)\n",
    "    def update(self, detections):\n",
    "        \"\"\"\n",
    "        detections: list of (state, box)\n",
    "        returns: list of confirmed entries (state, box) newly confirmed this frame\n",
    "        \"\"\"\n",
    "        now = time.time()\n",
    "        matched_idx = set()\n",
    "        # try to match detections to existing entries\n",
    "        for state, box in detections:\n",
    "            best_i = None; best_iou = 0.0\n",
    "            for i, e in enumerate(self.entries):\n",
    "                iouv = iou(box, e['box'])\n",
    "                if iouv > best_iou:\n",
    "                    best_i = i; best_iou = iouv\n",
    "            if best_i is not None and best_iou >= self.iou_thresh:\n",
    "                e = self.entries[best_i]\n",
    "                # state match increases confidence, mismatch reduces/overwrites\n",
    "                if e['state'] == state:\n",
    "                    e['count'] += 1\n",
    "                else:\n",
    "                    # different state observed for same box -> reset count and adopt new state\n",
    "                    e['state'] = state\n",
    "                    e['count'] = 1\n",
    "                e['box'] = box\n",
    "                e['last_seen'] = now\n",
    "                matched_idx.add(best_i)\n",
    "            else:\n",
    "                # new entry\n",
    "                self.entries.append({'state':state, 'box':box, 'count':1, 'last_seen':now, 'confirmed':False})\n",
    "        # age out stale entries (not seen for a while)\n",
    "        keep = []\n",
    "        for e in self.entries:\n",
    "            if now - e['last_seen'] > 1.0:   # 1s stale threshold\n",
    "                # don't keep if stale and not confirmed\n",
    "                if e.get('confirmed', False):\n",
    "                    keep.append(e)\n",
    "                else:\n",
    "                    # drop\n",
    "                    pass\n",
    "            else:\n",
    "                keep.append(e)\n",
    "        self.entries = keep\n",
    "        # check confirm\n",
    "        newly_confirmed = []\n",
    "        for e in self.entries:\n",
    "            if not e.get('confirmed', False) and e['count'] >= self.required_cons:\n",
    "                e['confirmed'] = True\n",
    "                newly_confirmed.append((e['state'], e['box']))\n",
    "                self.confirmed.append(e)\n",
    "        return newly_confirmed\n",
    "    def get_confirmed(self):\n",
    "        # return list of confirmed entries current\n",
    "        return [(e['state'], e['box']) for e in self.confirmed]\n",
    "\n",
    "# ---------------- Main processing: apply detector + temporal confirmation ----------------\n",
    "if not VIDEO_PATH.exists():\n",
    "    raise SystemExit(\"Video not found: \" + str(VIDEO_PATH))\n",
    "\n",
    "cap = cv2.VideoCapture(str(VIDEO_PATH))\n",
    "if not cap.isOpened():\n",
    "    raise SystemExit(\"Cannot open video.\")\n",
    "W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)); H = int(cap.get(cap.get if False else cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "FPS = cap.get(cv2.CAP_PROP_FPS) or 25.0\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"avc1\")\n",
    "out = cv2.VideoWriter(str(OUT_VIDEO), fourcc, FPS, (W, H))\n",
    "\n",
    "tracker_tl = TLConfirmTracker()\n",
    "events = []\n",
    "last_beep = -9999\n",
    "frame_id = 0\n",
    "t0 = time.time()\n",
    "print(\"Starting TL detection + confirmation pass...\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    detections = detect_tl_shapes(frame)  # returns list of (state, box)\n",
    "    # update confirmation tracker\n",
    "    newly_confirmed = tracker_tl.update(detections)\n",
    "    confirmed_now = tracker_tl.get_confirmed()\n",
    "\n",
    "    # draw detections (unconfirmed) faintly\n",
    "    for st, box in detections:\n",
    "        x1,y1,x2,y2 = map(int, box)\n",
    "        cv2.rectangle(frame, (x1,y1), (x2,y2), (200,200,200), 1)\n",
    "        cv2.putText(frame, f\"{st}\", (x1, max(0,y1-8)), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (200,200,200), 1)\n",
    "\n",
    "    # draw confirmed TLs with strong color\n",
    "    for st, box in confirmed_now:\n",
    "        x1,y1,x2,y2 = map(int, box)\n",
    "        color = (0,0,255) if st=='red' else (0,255,255) if st=='yellow' else (0,255,0)\n",
    "        cv2.rectangle(frame, (x1,y1), (x2,y2), color, 2)\n",
    "        cv2.putText(frame, f\"TL:{st}\", (x1, max(0,y1-8)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "        # beep on red (confirmed)\n",
    "        if st == 'red' and BEEP_ON_RED:\n",
    "            now = time.time()\n",
    "            if now - last_beep >= COOLDOWN_SECS:\n",
    "                last_beep = now\n",
    "                try:\n",
    "                    import winsound\n",
    "                    winsound.Beep(700, 180)\n",
    "                except Exception:\n",
    "                    pass\n",
    "        # log event\n",
    "        events.append({\"frame\":frame_id, \"time_s\":frame_id/FPS, \"state\":st, \"bbox\":str(box)})\n",
    "\n",
    "    # HUD summary\n",
    "    confirmed_states = \", \".join([f\"{s}\" for s,_ in confirmed_now]) if confirmed_now else \"none\"\n",
    "    cv2.putText(frame, f\"Confirmed TLs: {confirmed_states}\", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "    out.write(frame)\n",
    "    frame_id += 1\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "# save CSV\n",
    "with open(OUT_CSV, \"w\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"frame\",\"time_s\",\"state\",\"bbox\"])\n",
    "    writer.writeheader()\n",
    "    for r in events:\n",
    "        writer.writerow(r)\n",
    "\n",
    "print(\"Done. Frames processed:\", frame_id, \"Output video:\", OUT_VIDEO, \"Events CSV:\", OUT_CSV)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (adas)",
   "language": "python",
   "name": "adas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
